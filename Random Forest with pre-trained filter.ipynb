{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PAD': ('Padding', 0, 0.0, 0, 0.0)}\n",
      "C:/Users/admin/Desktop/DATASET/family/allaple_woj_g_98_year2017/\n",
      "C:/Users/admin/Desktop/DATASET/family/bettersurf_woj_g_137+/\n",
      "C:/Users/admin/Desktop/DATASET/family/elkern_woj_g_127/\n",
      "C:/Users/admin/Desktop/DATASET/family/graftor_g_18/\n",
      "C:/Users/admin/Desktop/DATASET/family/hotbar_g_32/\n",
      "C:/Users/admin/Desktop/DATASET/family/kryptik_g_529/\n",
      "C:/Users/admin/Desktop/DATASET/family/kryptik_g_547/\n",
      "C:/Users/admin/Desktop/DATASET/family/loadmoney_g_183/\n",
      "C:/Users/admin/Desktop/DATASET/family/loring_g_15/\n",
      "C:/Users/admin/Desktop/DATASET/family/mydoom_g_13/\n",
      "C:/Users/admin/Desktop/DATASET/family/rahack_g_39/\n",
      "C:/Users/admin/Desktop/DATASET/family/sytro_woj_g_166/\n",
      "C:/Users/admin/Desktop/DATASET/family/vobfus_g_111/\n",
      "C:/Users/admin/Desktop/DATASET/family/zbot_g_37/\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%run LoadModel.ipynb\n",
    "%run C:/Users/admin/Dropbox/Code/example/Data_input.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1751, 128)\n",
      "(1751, 14)\n",
      "(189, 128)\n",
      "(189, 14)\n",
      "(1751, 128)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "raw_x_train = np.ndarray(shape = (len(xx_train_list), img_rows*img_cols), buffer = np.array(xx_train_list))\n",
    "y_train = np.array(yy_train_list)\n",
    "\n",
    "print(raw_x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "#x_test = x_train.copy()\n",
    "#y_test = y_train.copy()\n",
    "\n",
    "raw_x_test= np.ndarray(shape = (len(xx_test_list), img_rows*img_cols), buffer = np.array(xx_test_list))\n",
    "y_test = np.array(yy_test_list)\n",
    "\n",
    "print(raw_x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "xx_train, xx_test = get_filter(raw_x_train, raw_x_test)\n",
    "\n",
    "x_train = raw_x_train*xx_train\n",
    "x_test = raw_x_test*xx_test\n",
    "\n",
    "batch_size = 24\n",
    "\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensor_forest.python import tensor_forest\n",
    "from tensorflow.python.ops import resources\n",
    "\n",
    "# Ignore all GPUs, tf random forest does not benefit from it.\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# None indicates that the first dimension, corresponding to the batch size, can be of any size.\n",
    "# Parameters\n",
    "num_steps = 5000 # Total steps to train\n",
    "batch_size = 24 # The number of samples per batch\n",
    "num_classes = 14 # The 10 digits\n",
    "num_features = 128 # Each image is 28x28 pixels\n",
    "num_trees = 14\n",
    "max_nodes = 100000\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_rows*img_cols])\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_next_batch(x_test, y_test, seq, start, batch_size):\n",
    "    end = start + batch_size\n",
    "    if end > len(x_test):\n",
    "        # Shuffle the data\n",
    "        perm = np.arange(len(x_test))\n",
    "        np.random.shuffle(perm)\n",
    "        # Start next epoch\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        seq = perm\n",
    "    return x_test[seq][start:end], y_test[seq][start:end], seq, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Parameters\n",
    "hparams = tensor_forest.ForestHParams(num_classes=num_classes,\n",
    "                                      num_features=num_features,\n",
    "                                      num_trees=num_trees,\n",
    "                                      max_nodes=max_nodes).fill()\n",
    "\n",
    "# Build the Random Forest\n",
    "forest_graph = tensor_forest.RandomForestGraphs(hparams)\n",
    "# Get training graph and loss\n",
    "train_op = forest_graph.training_graph(x, y)\n",
    "loss_op = forest_graph.training_loss(x, y)\n",
    "\n",
    "# Measure the accuracy\n",
    "infer_op1, infer_op2, infer_op3 = forest_graph.inference_graph(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1702: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "correct_prediction = tf.equal(tf.argmax(infer_op1, 1), tf.argmax(y, 1))\n",
    "\n",
    "accuracy_op = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "# Initialize the variables (i.e. assign their default value) and forest resources\n",
    "init_vars = tf.group(tf.global_variables_initializer(), resources.initialize_resources(resources.shared_resources()))\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "# # Run the initializer\n",
    "sess.run(init_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1, Loss: -1.000000, Acc: 1.000000\n",
      "Step 50, Loss: -7.285714, Acc: 0.000000\n",
      "Step 100, Loss: -14.428572, Acc: 0.333333\n",
      "Step 150, Loss: -22.142857, Acc: 0.416667\n",
      "Step 200, Loss: -30.571428, Acc: 0.291667\n",
      "Step 250, Loss: -37.714287, Acc: 0.250000\n",
      "Step 300, Loss: -45.000000, Acc: 0.416667\n",
      "Step 350, Loss: -51.428570, Acc: 0.500000\n",
      "Step 400, Loss: -58.714287, Acc: 0.208333\n",
      "Step 450, Loss: -65.000000, Acc: 0.208333\n",
      "Step 500, Loss: -72.142860, Acc: 0.333333\n",
      "Step 550, Loss: -78.428574, Acc: 0.500000\n",
      "Step 600, Loss: -84.142860, Acc: 0.416667\n",
      "Step 650, Loss: -91.714287, Acc: 0.208333\n",
      "Step 700, Loss: -96.571426, Acc: 0.291667\n",
      "Step 750, Loss: -102.428574, Acc: 0.250000\n",
      "Step 800, Loss: -108.142860, Acc: 0.291667\n",
      "Step 850, Loss: -114.428574, Acc: 0.333333\n",
      "Step 900, Loss: -121.000000, Acc: 0.166667\n",
      "Step 950, Loss: -127.142860, Acc: 0.458333\n",
      "Step 1000, Loss: -133.000000, Acc: 0.458333\n",
      "Step 1050, Loss: -137.571426, Acc: 0.458333\n",
      "Step 1100, Loss: -142.857147, Acc: 0.333333\n",
      "Step 1150, Loss: -148.714279, Acc: 0.500000\n",
      "Step 1200, Loss: -156.571426, Acc: 0.458333\n",
      "Step 1250, Loss: -160.000000, Acc: 0.416667\n",
      "Step 1300, Loss: -165.142853, Acc: 0.333333\n",
      "Step 1350, Loss: -169.571426, Acc: 0.375000\n",
      "Step 1400, Loss: -174.000000, Acc: 0.166667\n",
      "Step 1450, Loss: -179.000000, Acc: 0.208333\n",
      "Step 1500, Loss: -183.714279, Acc: 0.458333\n",
      "Step 1550, Loss: -187.571426, Acc: 0.416667\n",
      "Step 1600, Loss: -192.285721, Acc: 0.375000\n",
      "Step 1650, Loss: -196.571426, Acc: 0.375000\n",
      "Step 1700, Loss: -201.571426, Acc: 0.625000\n",
      "Step 1750, Loss: -205.857147, Acc: 0.208333\n",
      "Step 1800, Loss: -210.857147, Acc: 0.250000\n",
      "Step 1850, Loss: -215.714279, Acc: 0.333333\n",
      "Step 1900, Loss: -220.571426, Acc: 0.208333\n",
      "Step 1950, Loss: -224.571426, Acc: 0.208333\n",
      "Step 2000, Loss: -228.857147, Acc: 0.333333\n",
      "Step 2050, Loss: -232.428574, Acc: 0.458333\n",
      "Step 2100, Loss: -236.142853, Acc: 0.333333\n",
      "Step 2150, Loss: -239.428574, Acc: 0.291667\n",
      "Step 2200, Loss: -243.857147, Acc: 0.291667\n",
      "Step 2250, Loss: -249.000000, Acc: 0.166667\n",
      "Step 2300, Loss: -253.428574, Acc: 0.166667\n",
      "Step 2350, Loss: -257.000000, Acc: 0.500000\n",
      "Step 2400, Loss: -262.285706, Acc: 0.208333\n",
      "Step 2450, Loss: -267.000000, Acc: 0.416667\n",
      "Step 2500, Loss: -270.428558, Acc: 0.458333\n",
      "Step 2550, Loss: -274.428558, Acc: 0.541667\n",
      "Step 2600, Loss: -278.571442, Acc: 0.291667\n",
      "Step 2650, Loss: -282.714294, Acc: 0.500000\n",
      "Step 2700, Loss: -286.285706, Acc: 0.333333\n",
      "Step 2750, Loss: -290.428558, Acc: 0.333333\n",
      "Step 2800, Loss: -294.000000, Acc: 0.250000\n",
      "Step 2850, Loss: -298.428558, Acc: 0.375000\n",
      "Step 2900, Loss: -300.571442, Acc: 0.250000\n",
      "Step 2950, Loss: -304.142853, Acc: 0.333333\n",
      "Step 3000, Loss: -307.714294, Acc: 0.291667\n",
      "Step 3050, Loss: -310.857147, Acc: 0.416667\n",
      "Step 3100, Loss: -315.142853, Acc: 0.458333\n",
      "Step 3150, Loss: -318.428558, Acc: 0.375000\n",
      "Step 3200, Loss: -322.428558, Acc: 0.333333\n",
      "Step 3250, Loss: -325.571442, Acc: 0.333333\n",
      "Step 3300, Loss: -329.571442, Acc: 0.333333\n",
      "Step 3350, Loss: -333.000000, Acc: 0.416667\n",
      "Step 3400, Loss: -336.142853, Acc: 0.375000\n",
      "Step 3450, Loss: -339.142853, Acc: 0.375000\n",
      "Step 3500, Loss: -343.285706, Acc: 0.416667\n",
      "Step 3550, Loss: -345.714294, Acc: 0.375000\n",
      "Step 3600, Loss: -348.571442, Acc: 0.416667\n",
      "Step 3650, Loss: -351.857147, Acc: 0.291667\n",
      "Step 3700, Loss: -354.571442, Acc: 0.250000\n",
      "Step 3750, Loss: -357.857147, Acc: 0.458333\n",
      "Step 3800, Loss: -360.571442, Acc: 0.333333\n",
      "Step 3850, Loss: -363.714294, Acc: 0.333333\n",
      "Step 3900, Loss: -366.142853, Acc: 0.333333\n",
      "Step 3950, Loss: -370.714294, Acc: 0.375000\n",
      "Step 4000, Loss: -373.714294, Acc: 0.375000\n",
      "Step 4050, Loss: -376.428558, Acc: 0.333333\n",
      "Step 4100, Loss: -379.714294, Acc: 0.416667\n",
      "Step 4150, Loss: -382.428558, Acc: 0.291667\n",
      "Step 4200, Loss: -385.857147, Acc: 0.208333\n",
      "Step 4250, Loss: -389.000000, Acc: 0.208333\n",
      "Step 4300, Loss: -392.857147, Acc: 0.291667\n",
      "Step 4350, Loss: -395.000000, Acc: 0.291667\n",
      "Step 4400, Loss: -398.714294, Acc: 0.375000\n",
      "Step 4450, Loss: -400.428558, Acc: 0.333333\n",
      "Step 4500, Loss: -402.571442, Acc: 0.208333\n",
      "Step 4550, Loss: -407.142853, Acc: 0.166667\n",
      "Step 4600, Loss: -410.285706, Acc: 0.458333\n",
      "Step 4650, Loss: -413.000000, Acc: 0.416667\n",
      "Step 4700, Loss: -416.714294, Acc: 0.500000\n",
      "Step 4750, Loss: -419.285706, Acc: 0.250000\n",
      "Step 4800, Loss: -422.428558, Acc: 0.375000\n",
      "Step 4850, Loss: -425.714294, Acc: 0.125000\n",
      "Step 4900, Loss: -428.571442, Acc: 0.291667\n",
      "Step 4950, Loss: -432.571442, Acc: 0.166667\n",
      "Step 5000, Loss: -434.857147, Acc: 0.500000\n",
      "Test Accuracy: 0.3227513\n"
     ]
    }
   ],
   "source": [
    "b = 0\n",
    "seq = np.arange(len(x_train))\n",
    "\n",
    "# Training\n",
    "for i in range(1, num_steps + 1):\n",
    "    # Prepare Data\n",
    "    # Get the next batch of MNIST data (only images are needed, not labels)\n",
    "    batch_x, batch_y, seq, b = my_next_batch(x_train, y_train, seq, b, batch_size)\n",
    "    \n",
    "    _, l = sess.run([train_op, loss_op], feed_dict={x: batch_x, y: batch_y})\n",
    "    \n",
    "    if i % 50 == 0 or i == 1:\n",
    "        acc = accuracy_op.eval(feed_dict={x: batch_x, y: batch_y})\n",
    "        print('Step %i, Loss: %f, Acc: %f' % (i, l, acc))\n",
    "\n",
    "# Test Model\n",
    "print(\"Test Accuracy:\", sess.run(accuracy_op, feed_dict={x: x_test, y: y_test}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
