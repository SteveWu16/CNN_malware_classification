{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PAD': ('Padding', 0, 0.0, 0, 0.0)}\n",
      "C:/Users/admin/Desktop/DATASET/family/allaple_woj_g_98_year2017/\n",
      "C:/Users/admin/Desktop/DATASET/family/bettersurf_woj_g_137+/\n",
      "C:/Users/admin/Desktop/DATASET/family/elkern_woj_g_127/\n",
      "C:/Users/admin/Desktop/DATASET/family/graftor_g_18/\n",
      "C:/Users/admin/Desktop/DATASET/family/hotbar_g_32/\n",
      "C:/Users/admin/Desktop/DATASET/family/kryptik_g_529/\n",
      "C:/Users/admin/Desktop/DATASET/family/kryptik_g_547/\n",
      "C:/Users/admin/Desktop/DATASET/family/loadmoney_g_183/\n",
      "C:/Users/admin/Desktop/DATASET/family/loring_g_15/\n",
      "C:/Users/admin/Desktop/DATASET/family/mydoom_g_13/\n",
      "C:/Users/admin/Desktop/DATASET/family/rahack_g_39/\n",
      "C:/Users/admin/Desktop/DATASET/family/sytro_woj_g_166/\n",
      "C:/Users/admin/Desktop/DATASET/family/vobfus_g_111/\n",
      "C:/Users/admin/Desktop/DATASET/family/zbot_g_37/\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%run C:/Users/admin/Dropbox/Code/example/Data_input.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1751\n",
      "(1751, 128)\n",
      "(1751, 14)\n",
      "(189, 128)\n",
      "(189, 14)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.ndarray(shape = (len(xx_train_list), img_rows*img_cols), buffer = np.array(xx_train_list))\n",
    "y_train = np.array(yy_train_list)\n",
    "\n",
    "print(x_train.shape[0])\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "#x_test = x_train.copy()\n",
    "#y_test = y_train.copy()\n",
    "\n",
    "x_test= np.ndarray(shape = (len(xx_test_list), img_rows*img_cols), buffer = np.array(xx_test_list))\n",
    "y_test = np.array(yy_test_list)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_cols])\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes])\n",
    "# keep_prob = tf.placeholder(\"float\")\n",
    "batch_size = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden_1 = 128\n",
    "\n",
    "# train\n",
    "f_w1 = tf.get_variable('Lf_w1', [n_hidden_1, n_hidden_1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "f_b1 = tf.get_variable('Lf_b1', [n_hidden_1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "f_w2 = tf.get_variable('Lf_w2', [n_hidden_1, n_hidden_1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "f_b2 = tf.get_variable('Lf_b2', [n_hidden_1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "layer_1 = tf.add(tf.matmul(x, f_w1), f_b1)\n",
    "\n",
    "rlayer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "layer_2 = tf.add(tf.matmul(rlayer_1, f_w2), f_b2)\n",
    "\n",
    "layer_2_sigmoid = tf.sigmoid(layer_2)\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "# 小於threshold的會變成 0\n",
    "This_NN_threshold = tf.to_float((layer_2_sigmoid > threshold))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_conv(NN_threshold, number):\n",
    "    output = tf.constant(0, tf.float32, shape=[batch_size, img_rows])\n",
    "    for i in range(number):\n",
    "        \n",
    "        if i == 0:\n",
    "            continue\n",
    "            \n",
    "        else:\n",
    "            temp = NN_threshold[:, i:]\n",
    "            zero_temp = tf.constant(0, shape=[batch_size, i])\n",
    "            zero_temp = tf.cast(zero_temp, tf.float32)\n",
    "            temp_c = tf.concat([temp, zero_temp], 1)\n",
    "                        \n",
    "        output += temp_c\n",
    "    \n",
    "    NN_threshold += output\n",
    "    \n",
    "    return NN_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = 4\n",
    "\n",
    "filter_addition = custom_conv(This_NN_threshold, number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 128)\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10000\n",
    "display_step = 500\n",
    "\n",
    "# tf Graph Input\n",
    "\n",
    "newx = tf.multiply(x, This_NN_threshold)\n",
    "\n",
    "print(newx.shape)\n",
    "\n",
    "# Set model weights\n",
    "W = tf.get_variable('Lo_w1', [img_cols, num_classes], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "b = tf.get_variable('Lo_b1', [num_classes], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "# Construct model\n",
    "pred = tf.nn.softmax(tf.matmul(newx, W) + b) # Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_zero = tf.reduce_sum(This_NN_threshold)\n",
    "\n",
    "# element-wise divided by 2 and sum up\n",
    "continuous = 1 / tf.reduce_sum(tf.div(filter_addition, number))\n",
    "\n",
    "alfa = 1\n",
    "beta = 1\n",
    "\n",
    "# Minimize error using cross entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(y*tf.log(pred), reduction_indices=1))\n",
    "\n",
    "newCost = alfa*cost + beta*num_zero\n",
    "\n",
    "# Gradient Descent\n",
    "# GradientDescentOptimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(newCost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Lf_w1:0', 'Lf_b1:0', 'Lf_w2:0', 'Lf_b2:0']\n",
      "['Lo_w1:0', 'Lo_b1:0']\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "\n",
    "# filter and Lenet\n",
    "Lf_vars = [var for var in tvars if 'Lf_' in var.name]\n",
    "Lo_vars = [var for var in tvars if 'Lo_' in var.name]\n",
    "\n",
    "print([v.name for v in Lf_vars])\n",
    "print([v.name for v in Lo_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_next_batch(x_test, y_test, seq, start, batch_size):\n",
    "    end = start + batch_size\n",
    "    if end > len(x_test):\n",
    "        # Shuffle the data\n",
    "        perm = np.arange(len(x_test))\n",
    "        np.random.shuffle(perm)\n",
    "        # Start next epoch\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        seq = perm\n",
    "    return x_test[seq][start:end], y_test[seq][start:end], seq, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0500 cost= 0.814747632\n",
      "Epoch: 1000 cost= 0.311754435\n",
      "Epoch: 1500 cost= 0.358745307\n",
      "Epoch: 2000 cost= 0.372986943\n",
      "Epoch: 2500 cost= 0.375280589\n",
      "Epoch: 3000 cost= 0.378403038\n",
      "Epoch: 3500 cost= 0.047063429\n",
      "Epoch: 4000 cost= 0.151376814\n",
      "Epoch: 4500 cost= 0.075726852\n",
      "Epoch: 5000 cost= 0.292674571\n",
      "Epoch: 5500 cost= 0.286223382\n",
      "Epoch: 6000 cost= 0.244702861\n",
      "Epoch: 6500 cost= 0.181873366\n",
      "Epoch: 7000 cost= 0.329681754\n",
      "Epoch: 7500 cost= 0.132594094\n",
      "Epoch: 8000 cost= 0.340273172\n",
      "Epoch: 8500 cost= 0.110037051\n",
      "Epoch: 9000 cost= 0.209266141\n",
      "Epoch: 9500 cost= 0.198336959\n",
      "Epoch: 10000 cost= 0.194802165\n",
      "Optimization Finished!\n",
      "Accuracy: 0.93650794\n"
     ]
    }
   ],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "b = 0\n",
    "seq = np.arange(len(x_train))\n",
    "\n",
    "# Start training\n",
    "    \n",
    "avg_cost = 0.\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "\n",
    "    batch_x, batch_y, seq, b = my_next_batch(x_train, y_train, seq, b, batch_size)\n",
    "\n",
    "    _, c, nzero, cont = sess.run([optimizer, cost, num_zero, continuous], feed_dict={x: batch_x, y: batch_y})\n",
    "\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c)) \n",
    "\n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "# Test model\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy:\", accuracy.eval(feed_dict={x: x_test, y: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layer1(layer, image, num_filters, cmap = 'gray'):\n",
    "    \n",
    "    output = sess.run(layer, feed_dict = {x: image})\n",
    "    \n",
    "    print(output.shape)\n",
    "    \n",
    "    count0 = 0\n",
    "    for i in range(128):\n",
    "        if output[0][i] == 0:\n",
    "            count0+=1\n",
    "    print('total ', count0, 'zeros')\n",
    "#     print(output.shape)\n",
    "\n",
    "    num_grids = int(math.ceil(math.sqrt(num_filters)))\n",
    "    #x_grids, y_grids = num_grids, num_grids\n",
    "    x_grids, y_grids = num_filters, 1\n",
    "    fig, axes = plt.subplots(x_grids, y_grids, figsize=(15,15))\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < x_grids * y_grids and i < num_filters:\n",
    "            img = output[i]\n",
    "            img = img.reshape(-1,128)\n",
    "            img2 = output[i]\n",
    "            img2 = img2.reshape(8,16)\n",
    "            ax.imshow(img, interpolation='nearest', cmap=cmap)\n",
    "            ax.set_title(str(i))\n",
    "            ax.imshow(img2, interpolation='nearest', cmap=cmap)\n",
    "            ax.set_title(str(i))\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "        \n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1.\n",
      " 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 0. 1. 0. 0. 1. 1. 0. 0. 1. 0. 1. 1. 0.\n",
      " 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 1. 0. 0. 0. 1. 1. 0. 1. 0. 0.\n",
      " 1. 1. 1. 0. 1. 1. 0. 1. 0. 1. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1.\n",
      " 1. 0. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 1. 0. 1.\n",
      " 1. 1. 0. 1. 1. 0. 1. 1.]\n",
      "(1751, 128)\n",
      "total  65 zeros\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "reshape_all_layer = x_train.reshape(-1, 128)\n",
    "\n",
    "cplr = sess.run(This_NN_threshold, feed_dict={x : reshape_all_layer})\n",
    "print(cplr[1])\n",
    "\n",
    "plot_layer1(This_NN_threshold, reshape_all_layer, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# %run LoadModel.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
