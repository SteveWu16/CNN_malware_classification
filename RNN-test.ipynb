{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 ['allaple_woj_g_98_year2017', 'bettersurf_woj_g_137+', 'elkern_woj_g_127', 'graftor_g_18', 'hotbar_g_32', 'kryptik_g_529', 'kryptik_g_547', 'loadmoney_g_183', 'loring_g_15', 'mydoom_g_13', 'rahack_g_39', 'sytro_woj_g_166', 'vobfus_g_111', 'zbot_g_37']\n",
      "{'Padding': ('Padding', 0, 0.0, 0, 0.0), 'CreateRemoteThread': ('CreateRemoteThread', 1, 0.038461538461538464, 3, 3.896038118836955e-06), 'OpenThread': ('OpenThread', 2, 0.07692307692307693, 14, 2.2077549340076075e-05), 'WinExec': ('WinExec', 3, 0.11538461538461539, 15, 4.155773993426085e-05), 'TerminateProcess': ('TerminateProcess', 4, 0.15384615384615385, 21, 6.883000676611953e-05), 'GetUrlCacheEntryInfo': ('GetUrlCacheEntryInfo', 5, 0.19230769230769232, 33, 0.00011168642607332604), 'WinHttpOpen': ('WinHttpOpen', 6, 0.23076923076923078, 75, 0.0002090873790442499), 'WinHttpConnect': ('WinHttpConnect', 7, 0.2692307692307692, 75, 0.00030648833201517376), 'WinHttpOpenRequest': ('WinHttpOpenRequest', 8, 0.3076923076923077, 75, 0.00040388928498609765), 'WinHttpSendRequest': ('WinHttpSendRequest', 9, 0.34615384615384615, 170, 0.0006246647783868584), 'CreateProcess': ('CreateProcess', 10, 0.38461538461538464, 426, 0.001177902191261706), 'ExitProcess': ('ExitProcess', 11, 0.4230769230769231, 618, 0.0019804860437421185), 'InternetOpen': ('InternetOpen', 12, 0.46153846153846156, 779, 0.0029921572752667812), 'CreateProcessInternal': ('CreateProcessInternal', 13, 0.5, 791, 0.004019412659266791), 'HttpSendRequest': ('HttpSendRequest', 14, 0.5384615384615384, 856, 0.005131082202508269), 'InternetConnect': ('InternetConnect', 15, 0.5769230769230769, 912, 0.0063154777906347034), 'RegDeleteKey': ('RegDeleteKey', 16, 0.6153846153846154, 1856, 0.008725826706821833), 'OpenProcess': ('OpenProcess', 17, 0.6538461538461539, 2019, 0.011347860360799104), 'CreateThread': ('CreateThread', 18, 0.6923076923076923, 3927, 0.016447774258356678), 'RegSetValue': ('RegSetValue', 19, 0.7307692307692307, 16433, 0.03778897239397257), 'RegCreateKey': ('RegCreateKey', 20, 0.7692307692307693, 18481, 0.06178986588538116), 'CopyFile': ('CopyFile', 21, 0.8076923076923077, 27247, 0.09717498276003132), 'RegEnumValue': ('RegEnumValue', 22, 0.8461538461538461, 51961, 0.16465566165766032), 'LoadLibrary': ('LoadLibrary', 23, 0.8846153846153846, 52652, 0.23303372800199476), 'CreateFile': ('CreateFile', 24, 0.9230769230769231, 143427, 0.41929941442547075), 'DeleteFile': ('DeleteFile', 25, 0.9615384615384616, 160671, 0.6279595279560215), 'RegQueryValue': ('RegQueryValue', 26, 1.0, 286476, 1.0)}\n",
      "Done\n",
      "(1751, 128)\n",
      "(1751, 14)\n",
      "(189, 128)\n",
      "(189, 14)\n"
     ]
    }
   ],
   "source": [
    "test_rate = 0.1\n",
    "%run C:/Users/admin/Dropbox/Code/example/Data_input.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1751, 128)\n",
      "(1751, 14)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.ndarray(shape = (len(xx_train_list), img_rows*img_cols), buffer = np.array(xx_train_list))\n",
    "y_train = np.array(yy_train_list)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189, 128)\n",
      "(189, 14)\n"
     ]
    }
   ],
   "source": [
    "x_test= np.ndarray(shape = (len(xx_test_list), img_rows*img_cols), buffer = np.array(xx_test_list))\n",
    "y_test = np.array(yy_test_list)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Layer\n",
    "https://brohrer.mcknote.com/zh-Hant/how_machine_learning_works/how_convolutional_neural_networks_work.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.contrib.layers.xavier_initializer_conv2d()\n",
    "\n",
    "def weight_variable(shape):\n",
    "#     initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initializer(shape))\n",
    "\n",
    "def bias_variable(shape):\n",
    "#     initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initializer(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'RNN'\n",
    "\n",
    "#unrolled through 28 time steps\n",
    "time_steps = 16\n",
    "n_input = int(128/time_steps)\n",
    "n_steps = time_steps\n",
    "#hidden LSTM units\n",
    "num_units = 128\n",
    "n_hidden = num_units\n",
    "#rows of 28 pixels\n",
    "\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, time_steps, n_input]) # None, 128\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes])\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "\n",
    "weights = {\n",
    "    \"w_fc\" : weight_variable([n_hidden, n_classes])\n",
    "}\n",
    "biases = {\n",
    "    \"b_fc\" : bias_variable([n_classes]) \n",
    "}\n",
    "\n",
    "x_transpose = tf.transpose(x, [1, 0, 2])\n",
    "x_reshape = tf.reshape(x_transpose, [-1, n_input])\n",
    "\n",
    "x_split = tf.split(x_reshape, n_steps, 0)\n",
    "\n",
    "lstm_cell = tf.contrib.rnn.BasicLSTMCell(n_hidden, forget_bias=0.5)\n",
    "h, states = tf.nn.static_rnn(lstm_cell, x_split, dtype=tf.float32)\n",
    "\n",
    "h_fc = tf.matmul(h[-1], weights['w_fc']) + biases['b_fc']\n",
    "y_ = h_fc\n",
    "\n",
    "batch_size = 24\n",
    "\n",
    "\n",
    "API_padding = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate\n",
    "learning_rate = 0.0001\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits = h_fc, labels = y))\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24 2000 189 500\n"
     ]
    }
   ],
   "source": [
    "# batch_size = 20\n",
    "training_epochs = 2000\n",
    "testing_size = len(x_test)\n",
    "print_interval = 500\n",
    "\n",
    "print(batch_size, training_epochs, testing_size, print_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_next_batch(x_test, y_test, seq, start, batch_size):\n",
    "    end = start + batch_size\n",
    "    if end > len(x_test):\n",
    "        # Shuffle the data\n",
    "        perm = np.arange(len(x_test))\n",
    "        np.random.shuffle(perm)\n",
    "        # Start next epoch\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        seq = perm\n",
    "    return x_test[seq][start:end], y_test[seq][start:end], seq, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, loss 2.94666, accuracy 0.000\n",
      "step 100, loss 2.42988, accuracy 0.083\n",
      "step 200, loss 1.42388, accuracy 0.417\n",
      "step 300, loss 1.48732, accuracy 0.583\n",
      "step 400, loss 1.07255, accuracy 0.708\n",
      "step 500, loss 1.13184, accuracy 0.708\n",
      "step 600, loss 0.35982, accuracy 1.000\n",
      "step 700, loss 0.61216, accuracy 0.792\n",
      "step 800, loss 0.66605, accuracy 0.833\n",
      "step 900, loss 0.30042, accuracy 0.917\n",
      "step 1000, loss 0.50871, accuracy 0.875\n",
      "step 1100, loss 0.69946, accuracy 0.667\n",
      "step 1200, loss 0.35090, accuracy 0.917\n",
      "step 1300, loss 0.43811, accuracy 0.833\n",
      "step 1400, loss 0.45590, accuracy 0.792\n",
      "step 1500, loss 0.57039, accuracy 0.875\n",
      "step 1600, loss 0.51625, accuracy 0.833\n",
      "step 1700, loss 0.62476, accuracy 0.792\n",
      "step 1800, loss 0.58792, accuracy 0.875\n",
      "step 1900, loss 0.27985, accuracy 0.917\n"
     ]
    }
   ],
   "source": [
    "dropout = 0.5\n",
    "\n",
    "init_op = tf.global_variables_initializer()\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(init_op)\n",
    "\n",
    "variables_names =[v.name for v in tf.trainable_variables()]\n",
    "\n",
    "b = 0 #start\n",
    "seq = np.arange(len(x_train))\n",
    "\n",
    "# print(seq)\n",
    "for i in range(training_epochs):\n",
    "    batch_x, batch_y, seq, b = my_next_batch(x_train, y_train, seq, b, batch_size)\n",
    "    \n",
    "    batch_x = np.reshape(batch_x, (batch_size, n_steps, n_input))\n",
    "    \n",
    "    cost_train, accuracy_train, states_train, rnn_out = sess.run([cost, accuracy, states, h[-1]], feed_dict = {x: batch_x, y: batch_y})\n",
    "    \n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        print(\"step %d, loss %.5f, accuracy %.3f\" % (i, cost_train, accuracy_train))\n",
    "    optimizer.run(feed_dict={x: batch_x, y: batch_y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.899471\n"
     ]
    }
   ],
   "source": [
    "x_test = np.reshape(x_test, (-1, n_steps, n_input))\n",
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: x_test, y: y_test, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1, 128 0.920635\n",
    "# 1, 64 0.899471\n",
    "# 1, 32 0.904762\n",
    "# 2, 128 0.931217\n",
    "# 2, 64 0.936508\n",
    "# 2, 32 0.931217"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = tf.constant(1, shape=[10, 1, 10])\n",
    "# b = tf.unstack(a, 1, 1)\n",
    "# print(b)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
