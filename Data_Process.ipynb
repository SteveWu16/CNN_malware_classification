{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1714: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "%run LoadModel.ipynb\n",
    "\n",
    "import math\n",
    "test_rate = 0.1\n",
    "img_rows, img_cols = 1, 128\n",
    "API_padding = False\n",
    "API_padding = True # with API padding and without API moving window\n",
    "API_moving = API_padding = True # with API padding and API moving window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run C:/Users/admin/Dropbox/Code/example/Hooklog3.ipynb\n",
    "Hooklog = Hooklog3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_directories = [\"C:/Users/admin/Desktop/DATASET/family/allaple_woj_g_98_year2017/\", \n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/bettersurf_woj_g_137+/\", \n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/elkern_woj_g_127/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/graftor_g_18/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/hotbar_g_32/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/kryptik_g_529/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/kryptik_g_547/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/loadmoney_g_183/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/loring_g_15/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/mydoom_g_13/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/rahack_g_39/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/sytro_woj_g_166/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/vobfus_g_111/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/zbot_g_37/\",\n",
    "                 ]\n",
    "in_parseFirstPar = False\n",
    "\n",
    "in_apifreq_dicts = [\"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_allaple_woj_g_98_year2017.pickle\", \n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_bettersurf_woj_g_137+.pickle\", \n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_elkern_woj_g_127.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_graftor_g_18.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_hotbar_g_32.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_kryptik_g_529.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_kryptik_g_547.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_loadmoney_g_183.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_loring_g_15.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_mydoom_g_13.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_rahack_g_39.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_sytro_woj_g_166.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_vobfus_g_111.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_zbot_g_37.pickle\"\n",
    "                   ]\n",
    "\n",
    "num_classes = len(in_directories)\n",
    "classnames = list(map(lambda x: x.split(\"/\")[-2], in_directories))\n",
    "# print(num_classes, classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['allaple_woj_g_98_year2017', 'bettersurf_woj_g_137+', 'elkern_woj_g_127', 'graftor_g_18', 'hotbar_g_32', 'kryptik_g_529', 'kryptik_g_547', 'loadmoney_g_183', 'loring_g_15', 'mydoom_g_13', 'rahack_g_39', 'sytro_woj_g_166', 'vobfus_g_111', 'zbot_g_37']\n"
     ]
    }
   ],
   "source": [
    "print(classnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PAD': ('Padding', 0, 0.0, 0, 0.0)}\n"
     ]
    }
   ],
   "source": [
    "adict = dict()\n",
    "\n",
    "adict['PAD'] = ('Padding', 0, 0.0, 0, 0.0)\n",
    "print(adict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Padding': ('Padding', 0, 0.0, 0, 0.0), 'CreateRemoteThread': ('CreateRemoteThread', 1, 0.038461538461538464, 3, 1.0472081430905207e-05), 'OpenThread': ('OpenThread', 2, 0.07692307692307693, 14, 4.8869713344224296e-05), 'WinExec': ('WinExec', 3, 0.11538461538461539, 15, 5.236040715452604e-05), 'TerminateProcess': ('TerminateProcess', 4, 0.15384615384615385, 21, 7.330457001633645e-05), 'GetUrlCacheEntryInfo': ('GetUrlCacheEntryInfo', 5, 0.19230769230769232, 33, 0.00011519289573995727), 'WinHttpOpen': ('WinHttpOpen', 6, 0.23076923076923078, 75, 0.0002618020357726302), 'WinHttpConnect': ('WinHttpConnect', 7, 0.2692307692307692, 75, 0.0002618020357726302), 'WinHttpOpenRequest': ('WinHttpOpenRequest', 8, 0.3076923076923077, 75, 0.0002618020357726302), 'WinHttpSendRequest': ('WinHttpSendRequest', 9, 0.34615384615384615, 170, 0.000593417947751295), 'CreateProcess': ('CreateProcess', 10, 0.38461538461538464, 426, 0.0014870355631885393), 'ExitProcess': ('ExitProcess', 11, 0.4230769230769231, 618, 0.0021572487747664724), 'InternetOpen': ('InternetOpen', 12, 0.46153846153846156, 779, 0.002719250478225052), 'CreateProcessInternal': ('CreateProcessInternal', 13, 0.5, 791, 0.002761138803948673), 'HttpSendRequest': ('HttpSendRequest', 14, 0.5384615384615384, 856, 0.002988033901618286), 'InternetConnect': ('InternetConnect', 15, 0.5769230769230769, 912, 0.003183512754995183), 'RegDeleteKey': ('RegDeleteKey', 16, 0.6153846153846154, 1856, 0.006478727711920021), 'OpenProcess': ('OpenProcess', 17, 0.6538461538461539, 2019, 0.007047710802999204), 'CreateThread': ('CreateThread', 18, 0.6923076923076923, 3927, 0.013707954593054916), 'RegSetValue': ('RegSetValue', 19, 0.7307692307692307, 16433, 0.05736257138468842), 'RegCreateKey': ('RegCreateKey', 20, 0.7692307692307693, 18481, 0.06451151230818637), 'CopyFile': ('CopyFile', 21, 0.8076923076923077, 27247, 0.09511093424929139), 'RegEnumValue': ('RegEnumValue', 22, 0.8461538461538461, 51961, 0.1813799410770885), 'LoadLibrary': ('LoadLibrary', 23, 0.8846153846153846, 52652, 0.18379201050000699), 'CreateFile': ('CreateFile', 24, 0.9230769230769231, 143427, 0.500659741130147), 'DeleteFile': ('DeleteFile', 25, 0.9615384615384616, 160671, 0.5608532651949901), 'RegQueryValue': ('RegQueryValue', 26, 1.0, 286476, 1.0)}\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "apifreq_dict = dict()\n",
    "_total = 0\n",
    "\n",
    "for pkf in in_apifreq_dicts:\n",
    "    with open(pkf, 'rb') as f:\n",
    "        this_dict = pickle.load(f)\n",
    "        this_dict['Padding'] = 0\n",
    "        for k in this_dict:\n",
    "            if k in apifreq_dict:\n",
    "                apifreq_dict[k] += this_dict[k]\n",
    "            else:\n",
    "                apifreq_dict[k] = this_dict[k]\n",
    "            _total += this_dict[k]\n",
    "\n",
    "s_dict = {item[0]: item for item in [(k, i, i/(len(apifreq_dict)-1), apifreq_dict[k], apifreq_dict[k]/286476) for i, k in enumerate(sorted(apifreq_dict, key = apifreq_dict.get, reverse=False))]}\n",
    "print(s_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padding\n",
      "CreateRemoteThread\n",
      "OpenThread\n",
      "WinExec\n",
      "TerminateProcess\n",
      "GetUrlCacheEntryInfo\n",
      "WinHttpOpen\n",
      "WinHttpConnect\n",
      "WinHttpOpenRequest\n",
      "WinHttpSendRequest\n",
      "CreateProcess\n",
      "ExitProcess\n",
      "InternetOpen\n",
      "CreateProcessInternal\n",
      "HttpSendRequest\n",
      "InternetConnect\n",
      "RegDeleteKey\n",
      "OpenProcess\n",
      "CreateThread\n",
      "RegSetValue\n",
      "RegCreateKey\n",
      "CopyFile\n",
      "RegEnumValue\n",
      "LoadLibrary\n",
      "CreateFile\n",
      "DeleteFile\n",
      "RegQueryValue\n"
     ]
    }
   ],
   "source": [
    "for key in s_dict:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "27\n",
      "['Padding', 'CreateRemoteThread', 'OpenThread', 'WinExec', 'TerminateProcess', 'GetUrlCacheEntryInfo', 'WinHttpOpen', 'WinHttpConnect', 'WinHttpOpenRequest', 'WinHttpSendRequest', 'CreateProcess', 'ExitProcess', 'InternetOpen', 'CreateProcessInternal', 'HttpSendRequest', 'InternetConnect', 'RegDeleteKey', 'OpenProcess', 'CreateThread', 'RegSetValue', 'RegCreateKey', 'CopyFile', 'RegEnumValue', 'LoadLibrary', 'CreateFile', 'DeleteFile', 'RegQueryValue']\n",
      "[0.0, 1.0472081430905207e-05, 4.8869713344224296e-05, 5.236040715452604e-05, 7.330457001633645e-05, 0.00011519289573995727, 0.0002618020357726302, 0.0002618020357726302, 0.0002618020357726302, 0.000593417947751295, 0.0014870355631885393, 0.0021572487747664724, 0.002719250478225052, 0.002761138803948673, 0.002988033901618286, 0.003183512754995183, 0.006478727711920021, 0.007047710802999204, 0.013707954593054916, 0.05736257138468842, 0.06451151230818637, 0.09511093424929139, 0.1813799410770885, 0.18379201050000699, 0.500659741130147, 0.5608532651949901, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# print(s_dict)\n",
    "key_li = []\n",
    "key_num = []\n",
    "for key in s_dict:\n",
    "    key_li.append(key)\n",
    "    key_num.append(s_dict[key][4])\n",
    "    \n",
    "print(len(key_li))\n",
    "print(len(key_num))\n",
    "print(key_li)\n",
    "print(key_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Users/admin/Desktop/DATASET/family/allaple_woj_g_98_year2017/\n",
      "C:/Users/admin/Desktop/DATASET/family/bettersurf_woj_g_137+/\n",
      "C:/Users/admin/Desktop/DATASET/family/elkern_woj_g_127/\n",
      "C:/Users/admin/Desktop/DATASET/family/graftor_g_18/\n",
      "C:/Users/admin/Desktop/DATASET/family/hotbar_g_32/\n",
      "C:/Users/admin/Desktop/DATASET/family/kryptik_g_529/\n",
      "C:/Users/admin/Desktop/DATASET/family/kryptik_g_547/\n",
      "C:/Users/admin/Desktop/DATASET/family/loadmoney_g_183/\n",
      "C:/Users/admin/Desktop/DATASET/family/loring_g_15/\n",
      "C:/Users/admin/Desktop/DATASET/family/mydoom_g_13/\n",
      "C:/Users/admin/Desktop/DATASET/family/rahack_g_39/\n",
      "C:/Users/admin/Desktop/DATASET/family/sytro_woj_g_166/\n",
      "C:/Users/admin/Desktop/DATASET/family/vobfus_g_111/\n",
      "C:/Users/admin/Desktop/DATASET/family/zbot_g_37/\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "xx_train_list = list()\n",
    "yy_train_list = list()\n",
    "\n",
    "x_train_raw = list()\n",
    "\n",
    "xx_test_list = list()\n",
    "yy_test_list = list()\n",
    "\n",
    "x_test_raw = list()\n",
    "\n",
    "train_name_list = list()\n",
    "test_name_list = list()\n",
    "\n",
    "minimum = 0 #最小長度\n",
    "maximum = 0 #最大長度\n",
    "total = 0 #長度總和\n",
    "count = 0\n",
    "\n",
    "name_dict = dict()\n",
    "W_Size = 128\n",
    "h_size = W_Size\n",
    "n_classes = num_classes\n",
    "\n",
    "for label, in_dir in enumerate(in_directories):\n",
    "    print(in_dir)\n",
    "    hl_list = next(os.walk(in_dir))[2] # get all filenames in the in_directory\n",
    "    hl_list = [os.path.join(in_dir, f) for f in hl_list] # filepathname list\n",
    "    hl_list = list(filter(lambda f: f.endswith(\".hooklog\"), hl_list)) # in case some non-hooklog file in the folder\n",
    "    \n",
    "    #shuffle list\n",
    "    random.shuffle(hl_list) # <-------------- random here\n",
    "    test_size = int(len(hl_list)*test_rate)\n",
    "\n",
    "    for i, file in enumerate(hl_list):\n",
    "        hl3 = Hooklog(file, in_parseFirstPar)\n",
    "        \n",
    "        li_li = list() # for hacking moving_window # 20171129\n",
    "        \n",
    "        #statistic\n",
    "        if count == 0:\n",
    "            minimum = len(hl3.li)\n",
    "        \n",
    "        if len(hl3.li) < minimum:\n",
    "            minimum = len(hl3.li)\n",
    "            minimum_name = file\n",
    "        \n",
    "        if len(hl3.li) > maximum:\n",
    "            maximum = len(hl3.li)\n",
    "            maximum_name = file\n",
    "            \n",
    "        total += len(hl3.li)\n",
    "        count += 1\n",
    "        \n",
    "        for start in range(0, len(hl3.li), h_size):\n",
    "            end = start + h_size\n",
    "            #print(hl3.digitname, start, end)\n",
    "            \n",
    "            li = list()\n",
    "            raw_li = list()\n",
    "            for (t, api) in hl3.li[start:end]:\n",
    "                li.append(s_dict[api][4]) # <-- encode\n",
    "                raw_li.append(s_dict[api][0])\n",
    "            # hack\n",
    "            if len(li) < h_size:\n",
    "                #print(\"!!! change img_cols to a smaller number\", len(hl3.li))\n",
    "                #print(hl3.digitname, \"has smaller size\", len(hl3.li), \"need img_cols\", str(img_cols))\n",
    "                if API_padding:\n",
    "                    #print(\"padding 1.0\", str(img_cols - len(hl3.li)))\n",
    "                    for _ in range(h_size - len(li)):\n",
    "                        li.append(0)\n",
    "                        raw_li.append('Padding')\n",
    "            li_li.append(li)\n",
    "            \n",
    "            if(i < test_size):\n",
    "                xx_test_list.extend([li])\n",
    "                x_test_raw.extend([raw_li])\n",
    "                a = [0] * n_classes\n",
    "                a[label] = 1\n",
    "                yy_test_list.extend([a])\n",
    "                test_name_list.append((hl3.digitname, start))\n",
    "                name_dict[hl3.digitname] = label\n",
    "            else:\n",
    "                xx_train_list.extend([li])\n",
    "                x_train_raw.extend([raw_li])\n",
    "                a = [0] * n_classes\n",
    "                a[label] = 1\n",
    "                yy_train_list.extend([a])\n",
    "                train_name_list.append((hl3.digitname, start))\n",
    "                name_dict[hl3.digitname] = label\n",
    "                \n",
    "            break; # stop moving window!! Must break!\n",
    "# print (\"malware length minimum:\", minimum)\n",
    "# print(\"name:\",minimum_name)\n",
    "# print(\"---------------------------\")\n",
    "# print (\"malware length maximum:\", maximum)\n",
    "# print(\"name:\",maximum_name)\n",
    "# print(\"---------------------------\")\n",
    "# print(\"count：\",count)\n",
    "# print (\"malware length average:\", float(total)/float(count))\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSV process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1751, 128)\n",
      "(1751, 14)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.ndarray(shape = (len(xx_train_list), img_rows*img_cols), buffer = np.array(xx_train_list))\n",
    "y_train = np.array(yy_train_list)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189, 128)\n",
      "(189, 14)\n"
     ]
    }
   ],
   "source": [
    "#x_test = x_train.copy()\n",
    "#y_test = y_train.copy()\n",
    "\n",
    "x_test= np.ndarray(shape = (len(xx_test_list), img_rows*img_cols), buffer = np.array(xx_test_list))\n",
    "y_test = np.array(yy_test_list)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1751, 128)\n",
      "(1751, 14)\n",
      "(189, 128)\n",
      "(189, 14)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "raw_x_train = np.ndarray(shape = (len(xx_train_list), img_rows*img_cols), buffer = np.array(xx_train_list))\n",
    "y_train = np.array(yy_train_list)\n",
    "\n",
    "print(raw_x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "#x_test = x_train.copy()\n",
    "#y_test = y_train.copy()\n",
    "\n",
    "raw_x_test= np.ndarray(shape = (len(xx_test_list), img_rows*img_cols), buffer = np.array(xx_test_list))\n",
    "y_test = np.array(yy_test_list)\n",
    "\n",
    "print(raw_x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "xx_train, xx_test = get_filter(raw_x_train, raw_x_test)\n",
    "\n",
    "x_train = raw_x_train*xx_train\n",
    "x_test = raw_x_test*xx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1940, 128)\n",
      "(1940, 14)\n"
     ]
    }
   ],
   "source": [
    "totalx = sess.run(tf.concat([x_train, x_test], 0))\n",
    "totaly = sess.run(tf.concat([y_train, y_test], 0))\n",
    "\n",
    "print(totalx.shape)\n",
    "print(totaly.shape)\n",
    "\n",
    "newy_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1940, 128)\n"
     ]
    }
   ],
   "source": [
    "total_fx = sess.run(tf.concat([xx_train, xx_test], 0))\n",
    "print(total_fx.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# y to raw name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(len(totaly[0]))\n",
    "print(totaly[0])\n",
    "for i in range(len(totaly)):\n",
    "    for j in range(len(totaly[0])):\n",
    "        if totaly[i][j] == 1:\n",
    "            newy_list.append(classnames[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940\n",
      "allaple_woj_g_98_year2017\n"
     ]
    }
   ],
   "source": [
    "print(len(newy_list))\n",
    "print(newy_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tempx = totalx.tolist()\n",
    "final = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tempx[0].append(newy_list[0])\n",
    "# print(tempx[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新增family name到 x 之後"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(totaly)):\n",
    "    tempx[i].append(newy_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tempx[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import csv\n",
    "\n",
    "# with open('C:/Users/admin/Desktop/output.csv', 'w', newline='') as csvfile:\n",
    "#     writer = csv.writer(csvfile)\n",
    "    \n",
    "#     for i in range(len(totaly)):\n",
    "#         writer.writerow(tempx[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd \n",
    "\n",
    "# pd.DataFrame(totalx).to_csv(\"C:/Users/admin/Desktop/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_keyli = []\n",
    "temp_li = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(total_fx)):\n",
    "    for j in range(128):\n",
    "        if total_fx[i][j]==1:\n",
    "            for key in s_dict:\n",
    "                if totalx[i][j]==s_dict[key][4]:\n",
    "                    temp_li.append(key)\n",
    "    x_keyli.append(temp_li)\n",
    "    temp_li = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LoadLibrary', 'LoadLibrary', 'LoadLibrary', 'RegQueryValue', 'LoadLibrary', 'RegEnumValue', 'LoadLibrary', 'LoadLibrary', 'LoadLibrary', 'RegCreateKey', 'RegSetValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'CreateThread', 'CreateThread', 'CreateThread', 'CreateThread', 'RegQueryValue', 'CreateThread', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'RegQueryValue', 'CreateFile', 'CreateFile', 'Padding', 'Padding', 'Padding', 'Padding', 'Padding', 'Padding', 'Padding', 'Padding', 'Padding', 'Padding', 'Padding', 'Padding', 'Padding']\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "n = 1\n",
    "\n",
    "print(x_keyli[n])\n",
    "print(len(x_keyli[n]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n",
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "if totaly[0][0]==1:\n",
    "    print('yes')\n",
    "\n",
    "print(totaly[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
