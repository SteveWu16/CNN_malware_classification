{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_directories = [\"C:/Users/admin/Desktop/DATASET/family/allaple_woj_g_98_year2017/\", \n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/bettersurf_woj_g_137+/\", \n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/elkern_woj_g_127/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/graftor_g_18/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/hotbar_g_32/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/kryptik_g_529/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/kryptik_g_547/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/loadmoney_g_183/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/loring_g_15/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/mydoom_g_13/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/rahack_g_39/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/sytro_woj_g_166/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/vobfus_g_111/\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/zbot_g_37/\",\n",
    "                 ]\n",
    "in_parseFirstPar = False\n",
    "\n",
    "in_apifreq_dicts = [\"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_allaple_woj_g_98_year2017.pickle\", \n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_bettersurf_woj_g_137+.pickle\", \n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_elkern_woj_g_127.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_graftor_g_18.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_hotbar_g_32.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_kryptik_g_529.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_kryptik_g_547.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_loadmoney_g_183.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_loring_g_15.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_mydoom_g_13.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_rahack_g_39.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_sytro_woj_g_166.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_vobfus_g_111.pickle\",\n",
    "                  \"C:/Users/admin/Desktop/DATASET/family/pickle/apifreq_dict_zbot_g_37.pickle\"\n",
    "                   ]\n",
    "\n",
    "num_classes = len(in_directories)\n",
    "classnames = list(map(lambda x: x.split(\"/\")[-2], in_directories))\n",
    "# print(num_classes, classnames)\n",
    "\n",
    "adict = dict()\n",
    "\n",
    "adict['PAD'] = ('Padding', 0, 0.0, 0, 0.0)\n",
    "# print(adict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "apifreq_dict = dict()\n",
    "_total = 0\n",
    "\n",
    "for pkf in in_apifreq_dicts:\n",
    "    with open(pkf, 'rb') as f:\n",
    "        this_dict = pickle.load(f)\n",
    "        this_dict['Padding'] = 0\n",
    "        for k in this_dict:\n",
    "            if k in apifreq_dict:\n",
    "                apifreq_dict[k] += this_dict[k]\n",
    "            else:\n",
    "                apifreq_dict[k] = this_dict[k]\n",
    "            _total += this_dict[k]\n",
    "\n",
    "s_dict = {item[0]: item for item in [(k, i, i/(len(apifreq_dict)-1), apifreq_dict[k], apifreq_dict[k]/286476) for i, k in enumerate(sorted(apifreq_dict, key = apifreq_dict.get, reverse=False))]}\n",
    "# print(s_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_y = ['allaple_woj_g_98_year2017', 'bettersurf_woj_g_137+', 'elkern_woj_g_127', 'graftor_g_18',\n",
    "                'hotbar_g_32', 'kryptik_g_529', 'kryptik_g_547', 'loadmoney_g_183', 'loring_g_15', 'mydoom_g_13',\n",
    "                'rahack_g_39', 'sytro_woj_g_166', 'vobfus_g_111', 'zbot_g_37']\n",
    "    \n",
    "test_rate = 0.1\n",
    "\n",
    "img_rows, img_cols = 1, 128\n",
    "filter_x, filter_y = 1, 16\n",
    "n_hidden_1 = 128\n",
    "n_input = img_cols\n",
    "n_classes = len(answer_y)\n",
    "num_classes = len(answer_y)\n",
    "x = tf.placeholder(tf.float32, shape=[None, img_rows*img_cols]) # None, 784\n",
    "y = tf.placeholder(tf.float32, shape=[None, num_classes]) # None, 8\n",
    "keep_prob = tf.placeholder(\"float\")\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') \n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 1, 4, 1], strides=[1, 1, 4, 1], padding='SAME')\n",
    "\n",
    "# train\n",
    "f_w1 = tf.get_variable('f_w1', [n_input, n_hidden_1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02), trainable=False)\n",
    "f_b1 = tf.get_variable('f_b1', [n_hidden_1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02), trainable=False)\n",
    "\n",
    "f_w2 = tf.get_variable('f_w2', [n_hidden_1, n_hidden_1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02), trainable=False)\n",
    "f_b2 = tf.get_variable('f_b2', [n_hidden_1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02), trainable=False)\n",
    "\n",
    "layer_1 = tf.add(tf.matmul(x, f_w1), f_b1)\n",
    "\n",
    "rlayer_1 = tf.nn.relu(layer_1)\n",
    "\n",
    "layer_2 = tf.add(tf.matmul(rlayer_1, f_w2), f_b2)\n",
    "\n",
    "layer_2_sigmoid = tf.sigmoid(layer_2)\n",
    "\n",
    "threshold = 0.5\n",
    "\n",
    "NN_threshold = tf.to_float((layer_2_sigmoid > threshold))\n",
    "\n",
    "L1 = 64\n",
    "L2 = 128\n",
    "fc = 1024\n",
    "\n",
    "newx = tf.multiply(x, NN_threshold)\n",
    "W_conv1 = tf.get_variable('L_w1', [filter_x, filter_y, 1, L1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02), trainable=False)\n",
    "b_conv1 = tf.get_variable('L_b1', [L1], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02), trainable=False)\n",
    "\n",
    "x_image = tf.reshape(newx, [-1, img_rows, img_cols, 1]) # [batch, in_height, in_width, in_channels] [-1, 28, 28, 1]\n",
    "\n",
    "output_conv1 = conv2d(x_image, W_conv1) + b_conv1 ###\n",
    "\n",
    "h_conv1 = tf.nn.relu(output_conv1)\n",
    "\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "W_conv2 = tf.get_variable('L_w2', [filter_x, filter_y, L1, L2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02), trainable=False)\n",
    "b_conv2 = tf.get_variable('L_b2', [L2], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02), trainable=False)\n",
    "\n",
    "output_conv2 = conv2d(h_pool1, W_conv2) + b_conv2 ###\n",
    "h_conv2 = tf.nn.relu(output_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "s = int(img_rows*img_cols/4/4) # hack here, 2d 2x2 2 layers = 1d 1x4 2 layers\n",
    "\n",
    "W_fc1 = tf.get_variable('L_w3', [1 * s * L2, fc], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02), trainable=False)\n",
    "b_fc1 = tf.get_variable('L_b3', [fc], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02), trainable=False)\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 1*s*L2]) # [-1, 7*7*64]\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "W_fc2 = tf.get_variable('L_w4', [fc, num_classes], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02), trainable=False)\n",
    "b_fc2 = tf.get_variable('L_b4', [num_classes], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02), trainable=False)\n",
    "\n",
    "predictions = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "# f_vars = [var for var in tvars if 'f_' in var.name]\n",
    "# L_vars = [var for var in tvars if 'L_' in var.name]\n",
    "# print([v.name for v in f_vars])\n",
    "# print([v.name for v in L_vars])\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "saver = tf.train.Saver()\n",
    "    \n",
    "saver.restore(sess, \"C:/Users/admin/Desktop/CNN_Model/Filter_CNN.ckpt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layer1(layer, image, num_filters, cmap = 'gray'):\n",
    "    \n",
    "    output = sess.run(layer, feed_dict = {x: image, keep_prob: 1.0})\n",
    "#     fig, ax = plt.subplots(figsize=(15, 3))\n",
    "#     first_array = output.reshape(8, int(img_cols/8))\n",
    "#     ax.imshow(first_array, cmap = 'gray')\n",
    "    \n",
    "    count0 = 0\n",
    "    for i in range(128):\n",
    "        if output[0][i] == 0:\n",
    "            count0+=1\n",
    "    print('total ', count0, 'zeros')\n",
    "    \n",
    "    num_grids = int(math.ceil(math.sqrt(num_filters)))\n",
    "    x_grids, y_grids = num_filters, 1\n",
    "    fig, axes = plt.subplots(x_grids, y_grids, figsize=(15,0.3))\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < x_grids * y_grids and i < 1:\n",
    "            img = output[0]\n",
    "            img = img.reshape(-1,128)\n",
    "            ax.imshow(img, interpolation='nearest', cmap=cmap)\n",
    "            ax.set_title(str(\"filter\"))\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conv_layer(layer, image, num_filters, title, cmap = 'viridis'):\n",
    "    \n",
    "    output = sess.run(layer, feed_dict = {x: image, keep_prob: 1.0})\n",
    "#     first_array = output.reshape(8, int(img_cols/8))\n",
    "#     plt.imshow(first_array)\n",
    "    \n",
    "    count0 = 0\n",
    "    for i in range(128):\n",
    "        if output[0][i] == 0:\n",
    "            count0+=1\n",
    "#     print('total ', count0, 'zeros')\n",
    "\n",
    "    num_grids = int(math.ceil(math.sqrt(num_filters)))\n",
    "    #x_grids, y_grids = num_grids, num_grids\n",
    "    x_grids, y_grids = num_filters, 1\n",
    "    fig, axes = plt.subplots(x_grids, y_grids, figsize=(15,0.3))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < x_grids * y_grids and i < 1:\n",
    "            img = output[:]\n",
    "            ax.imshow(img, interpolation='nearest', cmap=cmap)\n",
    "            ax.set_title(title)\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cnn_layer(layer, image, num_filters, title):\n",
    "    \n",
    "    output = sess.run(layer, feed_dict = {x: image, keep_prob : 1.0})\n",
    "\n",
    "    num_grids = int(math.ceil(math.sqrt(num_filters)))\n",
    "    #x_grids, y_grids = num_grids, num_grids\n",
    "    x_grids, y_grids = num_filters, 1\n",
    "    fig, axes = plt.subplots(x_grids, y_grids, figsize=(15,0.3))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < x_grids * y_grids and i < 1:\n",
    "            img = output[0, :, :, i]\n",
    "            ax.imshow(img, interpolation='nearest')\n",
    "            ax.set_title(ax.set_title(str(title)))\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Filter_CNN(test_data):\n",
    "    test_data = test_data.reshape(-1, 128)\n",
    "    prediction_answer = sess.run(predictions,feed_dict={x: test_data, keep_prob: 1})\n",
    "#     print(prediction_answer.shape)\n",
    "    \n",
    "    img = prediction_answer\n",
    "    img = img.reshape(1, num_classes)\n",
    "    \n",
    "    num_grids = int(math.ceil(math.sqrt(1)))\n",
    "    #x_grids, y_grids = num_grids, num_grids\n",
    "    x_grids, y_grids = 2, 1\n",
    "    fig, axes = plt.subplots(x_grids, y_grids, figsize=(15,0.7))\n",
    "    \n",
    "    Index = int(list(prediction_answer[0]).index(max(prediction_answer[0])))\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < x_grids * y_grids and i < 1:\n",
    "            img = prediction_answer\n",
    "            ax.imshow(img, interpolation='nearest')\n",
    "            ax.set_title(ax.set_title(str(\"Prediction: this malware belongs to \" + answer_y[Index] + \" family\")))\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "    \n",
    "#     plt.imshow(img)\n",
    "#     Index = int(list(prediction_answer[0]).index(max(prediction_answer[0])))\n",
    "#     title = str(\"Prediction: this malware belongs to \" + answer_y[Index] + \" family\")\n",
    "#     plt.title(title)\n",
    "\n",
    "#     plt.title(prediction_answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(x):\n",
    "    API_moving = API_padding = True\n",
    "    h_size = 128\n",
    "    %run C:/Users/admin/Dropbox/Code/example/Hooklog3.ipynb\n",
    "    Hooklog = Hooklog3\n",
    "    hl3 = Hooklog(x, False)\n",
    "    li_li = list()\n",
    "\n",
    "    for start in range(0, len(hl3.li), h_size):\n",
    "        end = start + h_size\n",
    "        #print(hl3.digitname, start, end)\n",
    "\n",
    "        li = list()\n",
    "        raw_li = list()\n",
    "        for (t, api) in hl3.li[start:end]:\n",
    "            li.append(s_dict[api][4]) # <-- encode\n",
    "            raw_li.append(s_dict[api][0])\n",
    "        # hack\n",
    "        if len(li) < h_size:\n",
    "            #print(\"!!! change img_cols to a smaller number\", len(hl3.li))\n",
    "            #print(hl3.digitname, \"has smaller size\", len(hl3.li), \"need img_cols\", str(img_cols))\n",
    "            if API_padding:\n",
    "                #print(\"padding 1.0\", str(img_cols - len(hl3.li)))\n",
    "                for _ in range(h_size - len(li)):\n",
    "                    li.append(0)\n",
    "                    raw_li.append('Padding')\n",
    "        li_li.append(li)\n",
    "\n",
    "    test_data = li_li[0]\n",
    "    return test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_input(data):\n",
    "    \n",
    "#     first_array = data.reshape(8, int(img_cols/8))\n",
    "#     plt.imshow(first_array)\n",
    "    \n",
    "#     num_grids = int(math.ceil(math.sqrt(1)))\n",
    "    #x_grids, y_grids = num_grids, num_grids\n",
    "    x_grids, y_grids = 2, 1\n",
    "    fig, axes = plt.subplots(x_grids, y_grids, figsize=(15,0.5))\n",
    "\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < x_grids * y_grids and i < 1:\n",
    "            img = data\n",
    "            img = img.reshape(-1,128)\n",
    "            ax.imshow(img, interpolation='nearest', cmap='viridis')\n",
    "            ax.set_title(str(\"input\"))\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path = \"C:/Users/admin/Desktop/DATASET/family/loring_g_15/0b8b8865bc82a03cfd3c88140431093db5afacd5fa6841b828afa04c70feef8e_3308.trace.hooklog\"\n",
    "# print(len(data))\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(path):\n",
    "    saver = tf.train.Saver()\n",
    "    data = get_data(path)\n",
    "    data = np.asarray(data)\n",
    "    reshape_layer = data.reshape(-1, 128)\n",
    "    \n",
    "    saver.restore(sess, \"C:/Users/admin/Desktop/CNN_Model/Filter_CNN.ckpt\")\n",
    "    print_input(data)\n",
    "    plot_layer1(NN_threshold, reshape_layer, 2)\n",
    "    plot_conv_layer(newx, reshape_layer, 2, title = \"filterd input\")\n",
    "    plot_cnn_layer(output_conv1, reshape_layer, 2, title = \"conv1\")\n",
    "    plot_cnn_layer(h_pool1, reshape_layer, 2, title = \"pooling1\")\n",
    "    plot_cnn_layer(output_conv2, reshape_layer, 2, title = \"conv2\")\n",
    "    plot_cnn_layer(h_pool2, reshape_layer, 2, title = \"pooling2\")\n",
    "    Filter_CNN(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer2(path):\n",
    "    saver = tf.train.Saver()\n",
    "    data = get_data(path)\n",
    "    data = np.asarray(data)\n",
    "    reshape_layer = data.reshape(-1, 128)\n",
    "    \n",
    "    saver.restore(sess, \"C:/Users/admin/Desktop/CNN_Model/Filter_CNN.ckpt\")\n",
    "    print_input(data)\n",
    "    plot_layer1(NN_threshold, reshape_layer, 2)\n",
    "    plot_conv_layer(newx, reshape_layer, 2, title = \"filterd input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_answer(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter_info(path):\n",
    "    \n",
    "    data = get_data(path)\n",
    "    data = np.asarray(data)\n",
    "    reshape_layer = data.reshape(1, 128)\n",
    "    \n",
    "    data_to_raw = []\n",
    "    after_filtered = []\n",
    "    filter_to_raw = []\n",
    "    \n",
    "    data_filter = sess.run(NN_threshold, feed_dict = {x: reshape_layer, keep_prob: 1.0})\n",
    "    \n",
    "    for i in range(128):\n",
    "        for key in s_dict:\n",
    "            if reshape_layer[0][i] == s_dict[key][4]:\n",
    "                data_to_raw.append(key)\n",
    "    for j in range(128):\n",
    "        if data_filter[0][j] == 1:\n",
    "            after_filtered.append(reshape_layer[0][j])\n",
    "    for k in range(len(after_filtered)):\n",
    "        for key in s_dict:\n",
    "            if after_filtered[k] == s_dict[key][4]:\n",
    "                filter_to_raw.append(key)\n",
    "    \n",
    "    return filter_to_raw\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filter(x_train, x_test):\n",
    "    \n",
    "    saver = tf.train.Saver()\n",
    "    saver.restore(sess, \"C:/Users/admin/Desktop/CNN_Model/Filter_CNN.ckpt\")\n",
    "    \n",
    "    reshape_train = x_train.reshape(-1, 128)\n",
    "    reshape_test = x_test.reshape(-1, 128)\n",
    "    \n",
    "    train_filter = sess.run(NN_threshold, feed_dict = {x: reshape_train, keep_prob: 1.0})\n",
    "    test_filter = sess.run(NN_threshold, feed_dict = {x: reshape_test, keep_prob: 1.0})\n",
    "    \n",
    "    return train_filter, test_filter"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
