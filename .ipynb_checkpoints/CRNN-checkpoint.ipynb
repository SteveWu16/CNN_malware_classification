{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "initializer = tf.contrib.layers.xavier_initializer()\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 1, img_rows*img_cols]) # (?, 128)\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, num_classes]) # None, 8\n",
    "# None indicates that the first dimension, corresponding to the batch size, can be of any size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):\n",
    "#     initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initializer(shape))\n",
    "\n",
    "def bias_variable(shape):\n",
    "#     initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initializer(shape))\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') # \"SAME\" tries to pad evenly left and right\n",
    "    #The stride of the sliding window for each dimension of input x. \n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 1, 4, 1], strides=[1, 1, 4, 1], padding='SAME') # [1, 2, 2, 1], [1, 2, 2, 1]\n",
    "\n",
    "def norm(l_input, lsize):\n",
    "    return tf.nn.lrn(l_input, lsize, bias=1.0, alpha=1, beta=0.5, name=None) # a 0.001 / 9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640\n",
      "(?, 128)\n",
      "(?, 1, 128)\n",
      "(?, 1, 640)\n",
      "640\n"
     ]
    }
   ],
   "source": [
    "L1 = 64\n",
    "L2 = 128\n",
    "\n",
    "\n",
    "C1 = 80\n",
    "C2 = 160\n",
    "C3 = 320\n",
    "lsize = 5\n",
    "\n",
    "\n",
    "# [1,16,1,64]\n",
    "W_conv1 = weight_variable([filter_x, filter_y, 1, C1]) # [filter_height, filter_width, in_channels, out_channels] [5, 5, 1, 32]\n",
    "b_conv1 = bias_variable([C1]) # 32\n",
    "\n",
    "# Convolution 1\n",
    "output_conv1 = conv2d(x_image, W_conv1) + b_conv1 ###\n",
    "h_conv1 = tf.nn.relu(output_conv1)\n",
    "# Pooling 1\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "#正規化\n",
    "norm1 = norm(h_pool1, lsize) \n",
    "\n",
    "\n",
    "W_conv2 = weight_variable([filter_x, filter_y, C1, C2]) # [5, 5, 32, 64]\n",
    "b_conv2 = bias_variable([C2]) # 64\n",
    "\n",
    "# Convolution 2\n",
    "output_conv2 = conv2d(norm1, W_conv2) + b_conv2 #######\n",
    "h_conv2 = tf.nn.relu(output_conv2)\n",
    "\n",
    "# Pooling 2\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#正規化\n",
    "norm2 = norm(h_pool2, lsize)\n",
    "\n",
    "W_conv3 = weight_variable([filter_x, filter_y, C2, C3]) # [5, 5, 32, 64]\n",
    "b_conv3 = bias_variable([C3]) # 64\n",
    "\n",
    "# Convolution 3\n",
    "output_conv3 = conv2d(norm2, W_conv3) + b_conv3 #######\n",
    "h_conv3 = tf.nn.relu(output_conv3)\n",
    "\n",
    "#Pooling 3\n",
    "h_pool3 = max_pool_2x2(h_conv3)\n",
    "\n",
    "#正規化\n",
    "norm3 = norm(h_pool3, lsize) \n",
    "\n",
    "# Densely Connected Layer\n",
    "s = int(img_rows*img_cols/4/4/4) # hack here, 2d 2x2 2 layers = 1d 1x4 2 layers\n",
    "print(s * C3)\n",
    "\n",
    "W_fc1 = weight_variable([1 * s * C3, 128]) # [7 * 7 * 64, 1024]\n",
    "b_fc1 = bias_variable([128]) # 1024\"\n",
    "\n",
    "h_pool2_flat = tf.reshape(norm3, [-1, 1*s*C3]) #######\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "print(h_fc1.shape)\n",
    "\n",
    "# Dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "\n",
    "Rx_train = tf.reshape(h_fc1_drop, [-1, 1, 128]) \n",
    "print(Rx_train.shape)\n",
    "\n",
    "Rx_train_pool = tf.reshape(norm3, [-1, 1, norm3[0].shape[1]*norm3[0].shape[2]])\n",
    "print(Rx_train_pool.shape)\n",
    "\n",
    "print(Rx_train_pool.shape[2])\n",
    "\n",
    "# # Readout Layer\n",
    "# W_fc2 = weight_variable([1024, num_classes])\n",
    "# b_fc2 = bias_variable([num_classes])\n",
    "\n",
    "# y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[<tf.Tensor 'unstack:0' shape=(?, 640) dtype=float32>]\n"
     ]
    }
   ],
   "source": [
    "#unrolled through 28 time steps\n",
    "time_steps = 1\n",
    "#hidden LSTM units\n",
    "num_units = 128\n",
    "\n",
    "# n_input = 128\n",
    "n_input = Rx_train_pool.shape[2] \n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "\n",
    "# learning_rate = 0.001\n",
    "#mnist is meant to be classified in 10 classes(0-9).\n",
    "#n_classes=10\n",
    "#size of batch\n",
    "batch_size = 20\n",
    "\n",
    "h_size = time_steps * n_input\n",
    "API_padding = True\n",
    "\n",
    "n_classes = num_classes\n",
    "\n",
    "# x=tf.placeholder(\"float\",[None, 1, time_steps*n_input])\n",
    "\n",
    "#weights and biases of appropriate shape to accomplish above task\n",
    "\n",
    "# out_weights=tf.Variable(tf.random_normal([num_units,n_classes]))\n",
    "# out_bias=tf.Variable(tf.random_normal([n_classes]))\n",
    "\n",
    "out_weights = tf.Variable(initializer([num_units, n_classes]))\n",
    "out_bias = tf.Variable(initializer([n_classes]))\n",
    "\n",
    "#processing the input tensor from [batch_size,n_steps,n_input] to \"time_steps\" number of [batch_size,n_input] tensors\n",
    "\n",
    "\n",
    "\n",
    "input_x = tf.unstack(Rx_train_pool, time_steps, 1)\n",
    "# input_x=tf.unstack(Rx_train, time_steps, 1)\n",
    "print(len(input_x))\n",
    "print(input_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lstm_layer=tf.contrib.rnn.BasicLSTMCell(num_units,forget_bias=1)\n",
    "lstm_layer = tf.contrib.rnn.BasicLSTMCell(num_units, forget_bias = 0.5) #128\n",
    "\n",
    "outputs, _ = tf.nn.static_rnn(lstm_layer, input_x, dtype = \"float32\") # Mike: I change it to tf.nn.\n",
    "    \n",
    "#converting last output of dimension [batch_size,num_units] to [batch_size,n_classes] by out_weight multiplication\n",
    "prediction=tf.matmul(outputs[-1], out_weights) + out_bias\n",
    "#print(type(prediction),prediction)\n",
    "\n",
    "y = y_\n",
    "\n",
    "#loss_function\n",
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=prediction, labels=y))\n",
    "\n",
    "#optimization\n",
    "opt = tf.train.RMSPropOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "\n",
    "#model evaluation\n",
    "correct_prediction = tf.equal(tf.argmax(prediction, 1),tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_next_batch(x_test, y_test, seq, start, batch_size):\n",
    "    end = start + batch_size\n",
    "    if end > len(x_test):\n",
    "        # Shuffle the data\n",
    "        perm = np.arange(len(x_test))\n",
    "        np.random.shuffle(perm)\n",
    "        # Start next epoch\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        seq = perm\n",
    "    return x_test[seq][start:end], y_test[seq][start:end], seq, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For epoch: 1000 Accuracy: 0.9 \n",
      " Loss: 0.11877334\n",
      "For epoch: 2000 Accuracy: 0.9 \n",
      " Loss: 0.121455036\n",
      "For epoch: 3000 Accuracy: 1.0 \n",
      " Loss: 0.018762313\n",
      "For epoch: 4000 Accuracy: 0.9 \n",
      " Loss: 0.09998382\n",
      "For epoch: 5000 Accuracy: 1.0 \n",
      " Loss: 0.05837627\n",
      "For epoch: 6000 Accuracy: 0.95 \n",
      " Loss: 0.055789184\n",
      "For epoch: 7000 Accuracy: 0.95 \n",
      " Loss: 0.05800587\n",
      "For epoch: 8000 Accuracy: 0.9 \n",
      " Loss: 0.2040009\n",
      "For epoch: 9000 Accuracy: 0.95 \n",
      " Loss: 0.08425506\n",
      "For epoch: 10000 Accuracy: 1.0 \n",
      " Loss: 0.035197504\n",
      "For epoch: 11000 Accuracy: 0.95 \n",
      " Loss: 0.12585326\n",
      "For epoch: 12000 Accuracy: 0.9 \n",
      " Loss: 0.097152516\n",
      "For epoch: 13000 Accuracy: 1.0 \n",
      " Loss: 0.06839474\n",
      "For epoch: 14000 Accuracy: 1.0 \n",
      " Loss: 0.0059785163\n",
      "For epoch: 15000 Accuracy: 0.9 \n",
      " Loss: 0.27864563\n",
      "For epoch: 16000 Accuracy: 0.9 \n",
      " Loss: 0.15295961\n",
      "For epoch: 17000 Accuracy: 0.9 \n",
      " Loss: 0.21834537\n",
      "For epoch: 18000 Accuracy: 1.0 \n",
      " Loss: 0.0024432428\n",
      "For epoch: 19000 Accuracy: 0.95 \n",
      " Loss: 0.27245823\n",
      "For epoch: 20000 Accuracy: 0.95 \n",
      " Loss: 0.11171077\n",
      "For epoch: 21000 Accuracy: 0.95 \n",
      " Loss: 0.085450575\n",
      "For epoch: 22000 Accuracy: 1.0 \n",
      " Loss: 0.062875755\n",
      "For epoch: 23000 Accuracy: 0.95 \n",
      " Loss: 0.08051395\n",
      "For epoch: 24000 Accuracy: 0.95 \n",
      " Loss: 0.08022235\n",
      "For epoch: 25000 Accuracy: 1.0 \n",
      " Loss: 0.00064034323\n",
      "For epoch: 26000 Accuracy: 0.95 \n",
      " Loss: 0.27938643\n",
      "For epoch: 27000 Accuracy: 1.0 \n",
      " Loss: 0.021572836\n",
      "For epoch: 28000 Accuracy: 0.95 \n",
      " Loss: 0.104738496\n",
      "For epoch: 29000 Accuracy: 0.95 \n",
      " Loss: 0.09398893\n",
      "For epoch: 30000 Accuracy: 1.0 \n",
      " Loss: 0.03865484\n",
      "For epoch: 31000 Accuracy: 1.0 \n",
      " Loss: 0.012435792\n",
      "For epoch: 32000 Accuracy: 0.95 \n",
      " Loss: 0.08129676\n",
      "For epoch: 33000 Accuracy: 0.9 \n",
      " Loss: 0.11776253\n",
      "For epoch: 34000 Accuracy: 1.0 \n",
      " Loss: 0.012824597\n",
      "For epoch: 35000 Accuracy: 0.95 \n",
      " Loss: 0.23459467\n",
      "For epoch: 36000 Accuracy: 0.95 \n",
      " Loss: 0.06337072\n",
      "For epoch: 37000 Accuracy: 0.95 \n",
      " Loss: 0.11438458\n",
      "For epoch: 38000 Accuracy: 0.9 \n",
      " Loss: 0.19528893\n",
      "For epoch: 39000 Accuracy: 1.0 \n",
      " Loss: 0.08567879\n",
      "For epoch: 40000 Accuracy: 1.0 \n",
      " Loss: 0.043900833\n",
      "For epoch: 41000 Accuracy: 0.95 \n",
      " Loss: 0.13330525\n",
      "For epoch: 42000 Accuracy: 0.9 \n",
      " Loss: 0.24230433\n",
      "For epoch: 43000 Accuracy: 0.9 \n",
      " Loss: 0.27591383\n",
      "For epoch: 44000 Accuracy: 0.95 \n",
      " Loss: 0.08274602\n",
      "For epoch: 45000 Accuracy: 1.0 \n",
      " Loss: 0.012811473\n",
      "For epoch: 46000 Accuracy: 0.95 \n",
      " Loss: 0.135104\n",
      "For epoch: 47000 Accuracy: 0.9 \n",
      " Loss: 0.17047718\n",
      "For epoch: 48000 Accuracy: 1.0 \n",
      " Loss: 0.011038841\n",
      "For epoch: 49000 Accuracy: 0.95 \n",
      " Loss: 0.06983151\n",
      "For epoch: 50000 Accuracy: 1.0 \n",
      " Loss: 0.087645575\n",
      "For epoch: 51000 Accuracy: 1.0 \n",
      " Loss: 0.022118501\n",
      "For epoch: 52000 Accuracy: 0.95 \n",
      " Loss: 0.11438451\n",
      "For epoch: 53000 Accuracy: 1.0 \n",
      " Loss: 0.023824543\n",
      "For epoch: 54000 Accuracy: 0.95 \n",
      " Loss: 0.07924102\n",
      "For epoch: 55000 Accuracy: 1.0 \n",
      " Loss: 0.04320461\n",
      "For epoch: 56000 Accuracy: 0.95 \n",
      " Loss: 0.2253737\n",
      "For epoch: 57000 Accuracy: 0.95 \n",
      " Loss: 0.073510244\n",
      "For epoch: 58000 Accuracy: 1.0 \n",
      " Loss: 0.05307584\n",
      "For epoch: 59000 Accuracy: 1.0 \n",
      " Loss: 0.02515417\n",
      "For epoch: 60000 Accuracy: 0.95 \n",
      " Loss: 0.09882413\n",
      "For epoch: 61000 Accuracy: 0.85 \n",
      " Loss: 0.14605817\n",
      "For epoch: 62000 Accuracy: 0.95 \n",
      " Loss: 0.043502085\n",
      "For epoch: 63000 Accuracy: 0.85 \n",
      " Loss: 0.1593353\n",
      "For epoch: 64000 Accuracy: 1.0 \n",
      " Loss: 0.0018898344\n",
      "For epoch: 65000 Accuracy: 0.95 \n",
      " Loss: 0.09867782\n",
      "For epoch: 66000 Accuracy: 1.0 \n",
      " Loss: 0.04400567\n",
      "For epoch: 67000 Accuracy: 1.0 \n",
      " Loss: 0.062978014\n",
      "For epoch: 68000 Accuracy: 0.95 \n",
      " Loss: 0.16208601\n",
      "For epoch: 69000 Accuracy: 0.9 \n",
      " Loss: 0.15590742\n",
      "For epoch: 70000 Accuracy: 0.95 \n",
      " Loss: 0.10810296\n",
      "For epoch: 71000 Accuracy: 0.95 \n",
      " Loss: 0.0470361\n",
      "For epoch: 72000 Accuracy: 1.0 \n",
      " Loss: 0.017488832\n",
      "For epoch: 73000 Accuracy: 0.9 \n",
      " Loss: 0.15277626\n",
      "For epoch: 74000 Accuracy: 1.0 \n",
      " Loss: 0.007415165\n",
      "For epoch: 75000 Accuracy: 1.0 \n",
      " Loss: 0.026582424\n",
      "For epoch: 76000 Accuracy: 0.85 \n",
      " Loss: 0.257701\n",
      "For epoch: 77000 Accuracy: 0.95 \n",
      " Loss: 0.095177755\n",
      "For epoch: 78000 Accuracy: 0.9 \n",
      " Loss: 0.29957235\n",
      "For epoch: 79000 Accuracy: 1.0 \n",
      " Loss: 0.0026897488\n",
      "For epoch: 80000 Accuracy: 1.0 \n",
      " Loss: 0.06053741\n",
      "For epoch: 81000 Accuracy: 0.95 \n",
      " Loss: 0.07494696\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-2f72b6f9a7bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m100000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     27\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;33m>\u001b[0m\u001b[1;36m100000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0msess\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbatch_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep_prob\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdrop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;36m0.0001\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "epoch = 1\n",
    "\n",
    "drop = 0.5\n",
    "\n",
    "b = 0\n",
    "seq = np.arange(len(x_train))\n",
    "t0 = time.time()\n",
    "\n",
    "total = 10000\n",
    "\n",
    "while epoch < total:\n",
    "    \n",
    "    batch_x, batch_y, seq, b = my_next_batch(x_train, y_train, seq, b, batch_size)\n",
    "    batch_x = batch_x.reshape((batch_size, time_steps, img_cols)) # b, 1, 128\n",
    "#     print(type(batch_x), batch_x.shape, type(batch_y), batch_y.shape)\n",
    "\n",
    "    sess.run(opt, feed_dict={x: batch_x, y: batch_y, keep_prob: drop, learning_rate: 0.001})\n",
    "    \n",
    "#     if epoch <= 100000:\n",
    "#         sess.run(opt, feed_dict={x: batch_x, y: batch_y, keep_prob: drop, learning_rate: 0.001})\n",
    "#     elif epoch >100000:\n",
    "#         sess.run(opt, feed_dict={x: batch_x, y: batch_y, keep_prob: drop, learning_rate: 0.0001})\n",
    "        \n",
    "    if epoch %1000 == 0:\n",
    "        acc = sess.run(accuracy, feed_dict = {x: batch_x, y: batch_y, keep_prob: drop})\n",
    "        los = sess.run(loss, feed_dict = {x: batch_x, y: batch_y, keep_prob: drop})\n",
    "        print(\"For epoch:\", epoch, \"Accuracy:\", acc, \"\\n\", \"Loss:\",los)\n",
    "#         if acc >=0.95:\n",
    "#             break\n",
    "\n",
    "    epoch += 1\n",
    "\n",
    "    \n",
    "print(\"For epoch:\", epoch, \"Accuracy:\", acc, \"\\n\", \"Loss:\",los)\n",
    "\n",
    "t1 = time.time()\n",
    "\n",
    "print(\"total time:\", t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing Accuracy: 0.95238096\n"
     ]
    }
   ],
   "source": [
    "test_data = x_test.reshape((-1, time_steps, img_cols))\n",
    "test_label = y_test\n",
    "print(\"Testing Accuracy:\", sess.run(accuracy, feed_dict = {x: test_data, y: test_label, keep_prob: 1.0, learning_rate: 0.0001}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
