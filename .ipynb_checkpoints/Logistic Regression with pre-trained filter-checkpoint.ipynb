{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1714: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PAD': ('Padding', 0, 0.0, 0, 0.0)}\n",
      "C:/Users/admin/Desktop/DATASET/family/allaple_woj_g_98_year2017/\n",
      "C:/Users/admin/Desktop/DATASET/family/bettersurf_woj_g_137+/\n",
      "C:/Users/admin/Desktop/DATASET/family/elkern_woj_g_127/\n",
      "C:/Users/admin/Desktop/DATASET/family/graftor_g_18/\n",
      "C:/Users/admin/Desktop/DATASET/family/hotbar_g_32/\n",
      "C:/Users/admin/Desktop/DATASET/family/kryptik_g_529/\n",
      "C:/Users/admin/Desktop/DATASET/family/kryptik_g_547/\n",
      "C:/Users/admin/Desktop/DATASET/family/loadmoney_g_183/\n",
      "C:/Users/admin/Desktop/DATASET/family/loring_g_15/\n",
      "C:/Users/admin/Desktop/DATASET/family/mydoom_g_13/\n",
      "C:/Users/admin/Desktop/DATASET/family/rahack_g_39/\n",
      "C:/Users/admin/Desktop/DATASET/family/sytro_woj_g_166/\n",
      "C:/Users/admin/Desktop/DATASET/family/vobfus_g_111/\n",
      "C:/Users/admin/Desktop/DATASET/family/zbot_g_37/\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%run LoadModel.ipynb\n",
    "%run C:/Users/admin/Dropbox/Code/example/Data_input.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1751, 128)\n",
      "(1751, 14)\n",
      "(189, 128)\n",
      "(189, 14)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "raw_x_train = np.ndarray(shape = (len(xx_train_list), img_rows*img_cols), buffer = np.array(xx_train_list))\n",
    "y_train = np.array(yy_train_list)\n",
    "\n",
    "print(raw_x_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "#x_test = x_train.copy()\n",
    "#y_test = y_train.copy()\n",
    "\n",
    "raw_x_test= np.ndarray(shape = (len(xx_test_list), img_rows*img_cols), buffer = np.array(xx_test_list))\n",
    "y_test = np.array(yy_test_list)\n",
    "\n",
    "print(raw_x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx_train, xx_test = get_filter(raw_x_train, raw_x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = raw_x_train*xx_train\n",
    "x_test = raw_x_test*xx_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.18379201 0.18379201 0.18379201 0.18379201 0.18379201 0.18379201\n",
      " 0.18379201 0.18379201 1.         1.         0.18379201 1.\n",
      " 0.18379201 0.50065974 1.         1.         0.18137994 0.18379201\n",
      " 1.         0.18379201 0.18379201 0.18379201 0.18379201 0.18379201\n",
      " 0.50065974 0.50065974 0.06451151 0.05736257 0.06451151 0.05736257\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         1.         1.         1.         1.\n",
      " 1.         1.         0.01370795 0.01370795 0.01370795 0.01370795\n",
      " 0.01370795 1.         1.         1.         1.         1.\n",
      " 0.50065974 0.50065974 0.50065974 0.50065974 0.50065974 0.50065974\n",
      " 0.50065974 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n",
      "[0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1.\n",
      " 0. 0. 0. 0. 1. 1. 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 0.\n",
      " 0. 0. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0.\n",
      " 0. 0. 0. 1. 1. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 1. 1. 1. 1. 1. 0. 0. 1.\n",
      " 0. 0. 1. 1. 1. 1. 1. 0.]\n",
      "[0.         0.         0.         0.18379201 0.18379201 0.\n",
      " 0.18379201 0.         1.         0.         0.         0.\n",
      " 0.18379201 0.         0.         0.         0.18137994 0.18379201\n",
      " 1.         0.         0.         0.         0.18379201 0.18379201\n",
      " 0.         0.         0.         0.         0.06451151 0.05736257\n",
      " 0.         1.         1.         1.         1.         0.\n",
      " 0.         0.         1.         1.         1.         1.\n",
      " 0.         1.         0.         0.         1.         0.\n",
      " 0.         0.         1.         0.         1.         0.\n",
      " 0.         0.         1.         1.         0.         0.\n",
      " 1.         1.         0.         0.         0.         0.\n",
      " 1.         0.         0.         1.         0.         0.\n",
      " 0.         0.         0.         1.         1.         0.\n",
      " 0.         1.         1.         0.         1.         0.\n",
      " 0.         0.         1.         1.         0.         1.\n",
      " 1.         0.         0.01370795 0.01370795 0.01370795 0.01370795\n",
      " 0.01370795 1.         1.         1.         1.         1.\n",
      " 0.         0.         0.         0.         0.50065974 0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(raw_x_train[0])\n",
    "print(xx_train[0])\n",
    "print(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "# keep_prob = tf.placeholder(\"float\")\n",
    "batch_size = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 10000\n",
    "display_step = 500\n",
    "\n",
    "Lx = tf.placeholder(tf.float32, shape=[None, img_rows*img_cols])\n",
    "Ly = tf.placeholder(tf.float32, shape=[None, num_classes])\n",
    "\n",
    "# Set model weights\n",
    "LW = tf.get_variable('LR_w1', [img_cols, num_classes], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "Lb = tf.get_variable('LR_b1', [num_classes], dtype=tf.float32, initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
    "\n",
    "# Construct model\n",
    "pred = tf.nn.softmax(tf.matmul(Lx, LW) + Lb) # Softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minimize error using cross entropy\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Ly*tf.log(pred), reduction_indices=1))\n",
    "\n",
    "# Gradient Descent\n",
    "# GradientDescentOptimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['LR_w1:0', 'LR_b1:0']\n"
     ]
    }
   ],
   "source": [
    "tvars = tf.trainable_variables()\n",
    "# filter and Lenet\n",
    "LR_vars = [var for var in tvars if 'LR_' in var.name]\n",
    "\n",
    "print([v.name for v in LR_vars])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_next_batch(x_test, y_test, seq, start, batch_size):\n",
    "    end = start + batch_size\n",
    "    if end > len(x_test):\n",
    "        # Shuffle the data\n",
    "        perm = np.arange(len(x_test))\n",
    "        np.random.shuffle(perm)\n",
    "        # Start next epoch\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        seq = perm\n",
    "    return x_test[seq][start:end], y_test[seq][start:end], seq, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1714: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0500 cost= 0.965007067\n",
      "Epoch: 1000 cost= 0.593993723\n",
      "Epoch: 1500 cost= 0.306588918\n",
      "Epoch: 2000 cost= 0.269783944\n",
      "Epoch: 2500 cost= 0.257413626\n",
      "Epoch: 3000 cost= 0.282909423\n",
      "Epoch: 3500 cost= 0.202628687\n",
      "Epoch: 4000 cost= 0.087953411\n",
      "Epoch: 4500 cost= 0.172582686\n",
      "Epoch: 5000 cost= 0.114993393\n",
      "Epoch: 5500 cost= 0.245085314\n",
      "Epoch: 6000 cost= 0.099154539\n",
      "Epoch: 6500 cost= 0.337306976\n",
      "Epoch: 7000 cost= 0.188520238\n",
      "Epoch: 7500 cost= 0.110570252\n",
      "Epoch: 8000 cost= 0.167998984\n",
      "Epoch: 8500 cost= 0.089422025\n",
      "Epoch: 9000 cost= 0.376787513\n",
      "Epoch: 9500 cost= 0.196678683\n",
      "Epoch: 10000 cost= 0.128208622\n",
      "Optimization Finished!\n",
      "Accuracy: 0.8888889\n"
     ]
    }
   ],
   "source": [
    "# Initialize the variables (i.e. assign their default value)\n",
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "# sess.run(tf.initializers.variables())\n",
    "\n",
    "b = 0\n",
    "seq = np.arange(len(x_train))\n",
    "\n",
    "avg_cost = 0.\n",
    "# Training cycle\n",
    "for epoch in range(training_epochs):\n",
    "    \n",
    "    batch_x, batch_y, seq, b = my_next_batch(x_train, y_train, seq, b, batch_size)\n",
    "    \n",
    "    _, c = sess.run([optimizer, cost], feed_dict={Lx: batch_x, Ly: batch_y})\n",
    "\n",
    "    if (epoch+1) % display_step == 0:\n",
    "        print(\"Epoch:\", '%04d' % (epoch+1), \"cost=\", \"{:.9f}\".format(c))\n",
    "        \n",
    "print(\"Optimization Finished!\")\n",
    "\n",
    "# Test model\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(Ly, 1))\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Accuracy:\", accuracy.eval(feed_dict={Lx: x_test, Ly: y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layer1(layer, image, num_filters, cmap = 'gray'):\n",
    "    \n",
    "#     output = sess.run(layer, feed_dict = {x: image})\n",
    "    \n",
    "#     print(output.shape)\n",
    "    output = image\n",
    "    count0 = 0\n",
    "    for i in range(128):\n",
    "        if image[0][i] == 0:\n",
    "            count0+=1\n",
    "    print('total ', count0, 'zeros')\n",
    "#     print(output.shape)\n",
    "\n",
    "    num_grids = int(math.ceil(math.sqrt(num_filters)))\n",
    "    #x_grids, y_grids = num_grids, num_grids\n",
    "    x_grids, y_grids = num_filters, 1\n",
    "    fig, axes = plt.subplots(x_grids, y_grids, figsize=(15,15))\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < x_grids * y_grids and i < num_filters:\n",
    "            img = output[i]\n",
    "            img = img.reshape(-1,128)\n",
    "            img2 = output[i]\n",
    "            img2 = img2.reshape(8,16)\n",
    "            ax.imshow(img, interpolation='nearest', cmap=cmap)\n",
    "            ax.set_title(str(i))\n",
    "            ax.imshow(img2, interpolation='nearest', cmap=cmap)\n",
    "            ax.set_title(str(i))\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "        \n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total  65 zeros\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# reshape_all_layer = x_train.reshape(-1, 128)\n",
    "reshape_all_layer = xx_train.reshape(-1, 128)\n",
    "\n",
    "# cplr = sess.run(NN_threshold, feed_dict={x : reshape_all_layer})\n",
    "# print(cplr[1])\n",
    "\n",
    "plot_layer1(NN_threshold, reshape_all_layer, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PAD': ('Padding', 0, 0.0, 0, 0.0)}\n",
      "C:/Users/admin/Desktop/DATASET/family/allaple_woj_g_98_year2017/\n",
      "C:/Users/admin/Desktop/DATASET/family/bettersurf_woj_g_137+/\n",
      "C:/Users/admin/Desktop/DATASET/family/elkern_woj_g_127/\n",
      "C:/Users/admin/Desktop/DATASET/family/graftor_g_18/\n",
      "C:/Users/admin/Desktop/DATASET/family/hotbar_g_32/\n",
      "C:/Users/admin/Desktop/DATASET/family/kryptik_g_529/\n",
      "C:/Users/admin/Desktop/DATASET/family/kryptik_g_547/\n",
      "C:/Users/admin/Desktop/DATASET/family/loadmoney_g_183/\n",
      "C:/Users/admin/Desktop/DATASET/family/loring_g_15/\n",
      "C:/Users/admin/Desktop/DATASET/family/mydoom_g_13/\n",
      "C:/Users/admin/Desktop/DATASET/family/rahack_g_39/\n",
      "C:/Users/admin/Desktop/DATASET/family/sytro_woj_g_166/\n",
      "C:/Users/admin/Desktop/DATASET/family/vobfus_g_111/\n",
      "C:/Users/admin/Desktop/DATASET/family/zbot_g_37/\n",
      "Done\n",
      "1751\n",
      "(1751, 128)\n",
      "(1751, 14)\n",
      "(189, 128)\n",
      "(189, 14)\n",
      "(?, 128)\n",
      "['Lf_w1:0', 'Lf_b1:0', 'Lf_w2:0', 'Lf_b2:0']\n",
      "['Lo_w1:0', 'Lo_b1:0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\Anaconda3\\envs\\gpu\\lib\\site-packages\\tensorflow\\python\\client\\session.py:1714: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0500 cost= 0.848485649\n",
      "Epoch: 1000 cost= 0.494277149\n",
      "Epoch: 1500 cost= 0.370776057\n",
      "Epoch: 2000 cost= 0.283762366\n",
      "Epoch: 2500 cost= 0.202503607\n",
      "Epoch: 3000 cost= 0.290210158\n",
      "Epoch: 3500 cost= 0.353293747\n",
      "Epoch: 4000 cost= 0.141725674\n",
      "Epoch: 4500 cost= 0.169247493\n",
      "Epoch: 5000 cost= 0.210661486\n",
      "Epoch: 5500 cost= 0.128172964\n",
      "Epoch: 6000 cost= 0.302311927\n",
      "Epoch: 6500 cost= 0.270391017\n",
      "Epoch: 7000 cost= 0.191831663\n",
      "Epoch: 7500 cost= 0.075094245\n",
      "Epoch: 8000 cost= 0.256703228\n",
      "Epoch: 8500 cost= 0.181539491\n",
      "Epoch: 9000 cost= 0.164535150\n",
      "Epoch: 9500 cost= 0.138987407\n",
      "Epoch: 10000 cost= 0.062555753\n",
      "Optimization Finished!\n",
      "Accuracy: 0.9259259\n",
      "[0. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 1. 1. 1. 0. 1.\n",
      " 0. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0.\n",
      " 1. 1. 0. 1. 1. 0. 0. 0. 0. 1. 0. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 0. 0.\n",
      " 1. 0. 1. 1. 1. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0.\n",
      " 0. 1. 0. 0. 1. 1. 0. 0.]\n",
      "(1751, 128)\n",
      "total  65 zeros\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run Logistic_Regression.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run Alignment.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-Trained   vs.   Self-Trained \n",
      "\n",
      "Padding \t Padding \t o 36\n",
      "Padding \t Padding \t o 35\n",
      "Padding \t Padding \t o 34\n",
      "Padding \t Padding \t o 33\n",
      "Padding \t Padding \t o 32\n",
      "Padding \t Padding \t o 31\n",
      "Padding \t Padding \t o 30\n",
      "Padding \t Padding \t o 29\n",
      "Padding \t Padding \t o 28\n",
      "Padding \t CreateFile \t x 27\n",
      "Padding \t -       \t l 28\n",
      "Padding \t -       \t l 29\n",
      "Padding \t -       \t l 30\n",
      "CreateFile \t CreateFile \t o 31\n",
      "RegQueryValue \t RegQueryValue \t o 30\n",
      "RegQueryValue \t RegQueryValue \t o 29\n",
      "RegQueryValue \t RegQueryValue \t o 28\n",
      "RegQueryValue \t -       \t l 27\n",
      "CreateThread \t CreateThread \t o 28\n",
      "CreateThread \t RegQueryValue \t x 27\n",
      "RegQueryValue \t RegQueryValue \t o 28\n",
      "CreateThread \t RegQueryValue \t x 27\n",
      "CreateThread \t RegQueryValue \t x 28\n",
      "CreateThread \t RegQueryValue \t x 29\n",
      "RegQueryValue \t RegQueryValue \t o 30\n",
      "RegQueryValue \t RegQueryValue \t o 29\n",
      "RegQueryValue \t RegQueryValue \t o 28\n",
      "RegQueryValue \t RegQueryValue \t o 27\n",
      "RegQueryValue \t RegQueryValue \t o 26\n",
      "RegQueryValue \t RegQueryValue \t o 25\n",
      "RegQueryValue \t RegQueryValue \t o 24\n",
      "RegQueryValue \t RegQueryValue \t o 23\n",
      "RegQueryValue \t RegQueryValue \t o 22\n",
      "RegQueryValue \t RegQueryValue \t o 21\n",
      "RegQueryValue \t RegQueryValue \t o 20\n",
      "RegQueryValue \t RegQueryValue \t o 19\n",
      "RegQueryValue \t RegQueryValue \t o 18\n",
      "RegQueryValue \t RegQueryValue \t o 17\n",
      "RegQueryValue \t RegQueryValue \t o 16\n",
      "RegQueryValue \t RegQueryValue \t o 15\n",
      "RegQueryValue \t RegQueryValue \t o 14\n",
      "RegQueryValue \t RegQueryValue \t o 13\n",
      "RegQueryValue \t RegQueryValue \t o 12\n",
      "RegQueryValue \t RegQueryValue \t o 11\n",
      "RegQueryValue \t RegQueryValue \t o 10\n",
      "RegQueryValue \t RegQueryValue \t o 9\n",
      "RegQueryValue \t RegQueryValue \t o 8\n",
      "RegQueryValue \t RegQueryValue \t o 7\n",
      "RegQueryValue \t RegQueryValue \t o 6\n",
      "RegQueryValue \t RegQueryValue \t o 5\n",
      "RegQueryValue \t RegQueryValue \t o 4\n",
      "-       \t RegCreateKey \t t 3\n",
      "RegSetValue \t RegSetValue \t o 4\n",
      "RegCreateKey \t RegCreateKey \t o 3\n",
      "-       \t CreateFile \t t 2\n",
      "LoadLibrary \t LoadLibrary \t o 3\n",
      "LoadLibrary \t LoadLibrary \t o 2\n",
      "RegQueryValue \t LoadLibrary \t x 1\n",
      "LoadLibrary \t LoadLibrary \t o 2\n",
      "RegEnumValue \t RegEnumValue \t o 1\n",
      "-       \t RegQueryValue \t t 0\n",
      "-       \t RegQueryValue \t t 1\n",
      "LoadLibrary \t LoadLibrary \t o 2\n",
      "RegQueryValue \t RegQueryValue \t o 1\n",
      "LoadLibrary \t LoadLibrary \t o 0\n",
      "LoadLibrary \t LoadLibrary \t o -1\n"
     ]
    }
   ],
   "source": [
    "align_i = 345\n",
    "\n",
    "x_raw = x_train[align_i]\n",
    "\n",
    "preTrained_filter = xx_train[align_i]\n",
    "SelfTrained_filter = sess.run(This_NN_threshold, feed_dict={x: x_raw.reshape(-1, 128)})[0]\n",
    "\n",
    "# pre-trained\n",
    "data_to_raw = []\n",
    "after_filtered1 = []\n",
    "filter_to_raw1 = []\n",
    "\n",
    "# self-trained\n",
    "after_filtered2 = []\n",
    "filter_to_raw2 = []\n",
    "\n",
    "# 原始的先還原\n",
    "for i in range(128):\n",
    "    for key in s_dict:\n",
    "        if x_raw[i] == s_dict[key][4]:\n",
    "            data_to_raw.append(key)\n",
    "\n",
    "# filter內有出現1 就還原成原始的code\n",
    "for j in range(128):\n",
    "    if preTrained_filter[j] == 1:\n",
    "        after_filtered1.append(data_to_raw[j])\n",
    "    if SelfTrained_filter[j] == 1:\n",
    "        after_filtered2.append(data_to_raw[j])\n",
    "\n",
    "print('Pre-Trained   vs.   Self-Trained \\n')\n",
    "get_align(after_filtered1, after_filtered2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s_dict[key][4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
