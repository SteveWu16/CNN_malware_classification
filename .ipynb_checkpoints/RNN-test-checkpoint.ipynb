{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PAD': ('Padding', 0, 0.0, 0, 0.0)}\n",
      "C:/Users/admin/Desktop/DATASET/family/allaple_woj_g_98_year2017/\n",
      "C:/Users/admin/Desktop/DATASET/family/bettersurf_woj_g_137+/\n",
      "C:/Users/admin/Desktop/DATASET/family/elkern_woj_g_127/\n",
      "C:/Users/admin/Desktop/DATASET/family/graftor_g_18/\n",
      "C:/Users/admin/Desktop/DATASET/family/hotbar_g_32/\n",
      "C:/Users/admin/Desktop/DATASET/family/kryptik_g_529/\n",
      "C:/Users/admin/Desktop/DATASET/family/kryptik_g_547/\n",
      "C:/Users/admin/Desktop/DATASET/family/loadmoney_g_183/\n",
      "C:/Users/admin/Desktop/DATASET/family/loring_g_15/\n",
      "C:/Users/admin/Desktop/DATASET/family/mydoom_g_13/\n",
      "C:/Users/admin/Desktop/DATASET/family/rahack_g_39/\n",
      "C:/Users/admin/Desktop/DATASET/family/sytro_woj_g_166/\n",
      "C:/Users/admin/Desktop/DATASET/family/vobfus_g_111/\n",
      "C:/Users/admin/Desktop/DATASET/family/zbot_g_37/\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "%run C:/Users/admin/Dropbox/Code/example/Data_input.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1751, 128)\n",
      "(1751, 14)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "x_train = np.ndarray(shape = (len(xx_train_list), img_rows*img_cols), buffer = np.array(xx_train_list))\n",
    "y_train = np.array(yy_train_list)\n",
    "\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(189, 128)\n",
      "(189, 14)\n"
     ]
    }
   ],
   "source": [
    "x_test= np.ndarray(shape = (len(xx_test_list), img_rows*img_cols), buffer = np.array(xx_test_list))\n",
    "y_test = np.array(yy_test_list)\n",
    "\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, shape=[None, img_rows*img_cols]) # None, 128\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, num_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Layer\n",
    "https://brohrer.mcknote.com/zh-Hant/how_machine_learning_works/how_convolutional_neural_networks_work.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "initializer = tf.contrib.layers.xavier_initializer_conv2d()\n",
    "\n",
    "def weight_variable(shape):\n",
    "#     initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initializer(shape))\n",
    "\n",
    "def bias_variable(shape):\n",
    "#     initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initializer(shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool_size = 4\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') # \"SAME\" tries to pad evenly left and right\n",
    "    #The stride of the sliding window for each dimension of input x. \n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 1, pool_size, 1], strides=[1, 1, pool_size, 1], padding='SAME') # [1, 2, 2, 1], [1, 2, 2, 1]\n",
    "\n",
    "def norm(l_input, lsize):\n",
    "#     return tf.nn.lrn(l_input, lsize, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name=None)\n",
    "    return tf.nn.lrn(l_input, lsize, bias=1.0, alpha=1.0, beta=0.5, name=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "C1 = 32\n",
    "C2 = 64\n",
    "C3 = 128\n",
    "lsize = 5\n",
    "filter_x, filter_y = 1, 4\n",
    "# [1,16,1,64]\n",
    "W_conv1 = weight_variable([filter_x, filter_y, 1, C1]) # [filter_height, filter_width, in_channels, out_channels] [5, 5, 1, 32]\n",
    "b_conv1 = bias_variable([C1]) # 32\n",
    "\n",
    "x_image = tf.reshape(x, [-1, img_rows, img_cols, 1]) # [batch, in_height, in_width, in_channels] [-1, 28, 28, 1]\n",
    "\n",
    "# Convolution 1\n",
    "output_conv1 = conv2d(x_image, W_conv1) + b_conv1 ###\n",
    "h_conv1 = tf.nn.relu(output_conv1)\n",
    "# Pooling 1\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "#正規化\n",
    "norm1 = norm(h_pool1, lsize) \n",
    "\n",
    "W_conv2 = weight_variable([filter_x, filter_y, C1, C2]) # [5, 5, 32, 64]\n",
    "b_conv2 = bias_variable([C2]) # 64\n",
    "\n",
    "# Convolution 2\n",
    "output_conv2 = conv2d(norm1, W_conv2) + b_conv2 ###\n",
    "h_conv2 = tf.nn.relu(output_conv2)\n",
    "\n",
    "# Pooling 2\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "#正規化\n",
    "norm2 = norm(h_pool2, lsize)\n",
    "\n",
    "W_conv3 = weight_variable([filter_x, filter_y, C2, C3]) # [5, 5, 32, 64]\n",
    "b_conv3 = bias_variable([C3]) # 64\n",
    "\n",
    "# Convolution 3\n",
    "output_conv3 = conv2d(norm2, W_conv3) + b_conv3 ###\n",
    "h_conv3 = tf.nn.relu(output_conv3)\n",
    "\n",
    "#Pooling 3\n",
    "h_pool3 = max_pool_2x2(h_conv3)\n",
    "\n",
    "#正規化\n",
    "norm3 = norm(h_pool3, lsize) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Densely Connected Layer\n",
    "fc = 1024\n",
    "\n",
    "s = int(img_rows*img_cols/pool_size/pool_size/pool_size) # hack here, 2d 2x2 2 layers = 1d 1x4 2 layers\n",
    "\n",
    "W_fc1 = weight_variable([1 * s * C3, fc]) # [7 * 7 * 64, 1024]\n",
    "b_fc1 = bias_variable([fc]) # 1024\"\n",
    "\n",
    "h_pool3_flat = tf.reshape(h_pool3, [-1, 1*s*C3]) # [-1, 7*7*64]\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool3_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Readout Layer\n",
    "W_fc2 = weight_variable([fc, num_classes]) # [1024, 8]\n",
    "b_fc2 = bias_variable([num_classes]) # 8\n",
    "\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate\n",
    "learning_rate = 0.001\n",
    "\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=y_conv))\n",
    "train_step = tf.train.AdamOptimizer(learning_rate).minimize(cross_entropy) # learning rate\n",
    "\n",
    "\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 3000 189 500\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "training_epochs = 3000\n",
    "testing_size = len(x_test)\n",
    "print_interval = 500\n",
    "\n",
    "print(batch_size, training_epochs, testing_size, print_interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_next_batch(x_test, y_test, seq, start, batch_size):\n",
    "    end = start + batch_size\n",
    "    if end > len(x_test):\n",
    "        # Shuffle the data\n",
    "        perm = np.arange(len(x_test))\n",
    "        np.random.shuffle(perm)\n",
    "        # Start next epoch\n",
    "        start = 0\n",
    "        end = batch_size\n",
    "        seq = perm\n",
    "    return x_test[seq][start:end], y_test[seq][start:end], seq, end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0, training accuracy 0\n",
      "step 500, training accuracy 0.85\n",
      "step 1000, training accuracy 0.75\n",
      "step 1500, training accuracy 0.85\n",
      "step 2000, training accuracy 0.85\n",
      "step 2500, training accuracy 0.85\n",
      "time 44.230334997177124\n"
     ]
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "dropout = 0.5\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "b = 0 #start\n",
    "seq = np.arange(len(x_train))\n",
    "\n",
    "# print(seq)\n",
    "for i in range(training_epochs):\n",
    "    batch_x, batch_y, seq, b = my_next_batch(x_train, y_train, seq, b, batch_size)\n",
    "    \n",
    "    if i%print_interval == 0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x: batch_x, y_: batch_y, keep_prob: dropout})\n",
    "#         if train_accuracy >= 0.95:\n",
    "#             break\n",
    "        print(\"step %d, training accuracy %g\"%(i, train_accuracy))\n",
    "            \n",
    "    train_step.run(feed_dict={x: batch_x, y_: batch_y, keep_prob: dropout})\n",
    "    \n",
    "end = time.time()\n",
    "elapsed = end - start\n",
    "print('time', elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.915344\n"
     ]
    }
   ],
   "source": [
    "print(\"test accuracy %g\"%accuracy.eval(feed_dict={x: x_test, y_: y_test, keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'htdtdytdhcg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-98fcfe95e7d8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhtdtdytdhcg\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'htdtdytdhcg' is not defined"
     ]
    }
   ],
   "source": [
    "htdtdytdhcg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print the digit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_layer(layer, image):\n",
    "    # layer 輸入範例是 [batch_num, width, height, channels] ex. [1, 28, 28, 32]\n",
    "    # 這裡設定的 image 是單一個手寫字影像輸入\n",
    "    # 接下來把它餵入 tensorflow 的 session 跑出我們想要的輸出結果\n",
    "#     sess = tf.InteractiveSession()\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    output = sess.run(layer, feed_dict = {x: [image]}) # 執行 Convolution / Pooling\n",
    "    \n",
    "    print('output.shape = ' + str(output.shape))\n",
    "    print(type(output))\n",
    "    print(output[0,0,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fc_layer(layer, image):\n",
    "#     sess = tf.InteractiveSession()\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    output = sess.run(layer, feed_dict = {x: [image]})\n",
    "    \n",
    "    fc = tf.nn.relu(tf.matmul(output, W_fc1) + b_fc1)\n",
    "    \n",
    "    sfc = sess.run(tf.reshape(fc,[1024]))\n",
    "    \n",
    "    print('output.shape = ' + str(fc.shape))\n",
    "    print(type(fc))\n",
    "    print(sfc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_ro_layer(layer, image):\n",
    "#     sess = tf.InteractiveSession()\n",
    "#     sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    output = sess.run(layer, feed_dict = {x: [image]})\n",
    "    \n",
    "#     h_fc1 = tf.nn.relu(tf.matmul(output, W_fc1) + b_fc1)\n",
    "    \n",
    "#     keep_prob = tf.placeholder(tf.float32)\n",
    "    \n",
    "    h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "    \n",
    "    y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "    \n",
    "    print('output.shape = ' + str(y_conv.shape))\n",
    "    print(type(y_conv))\n",
    "    print(sess.run(y_conv, feed_dict = {x: [image], keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def tsne(X, n_components):\n",
    "    model = TSNE(n_components=2, perplexity=40)\n",
    "    return model.fit_transform(X)\n",
    "\n",
    "def pca(X, n_components):\n",
    "    pca = PCA(n_components = n_components)\n",
    "    pca.fit(X)\n",
    "    return pca.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(x, labels):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(x[:,0], x[:,1], c = labels, cmap = \"tab10\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size = len(x_test)\n",
    "test_data = x_test[0:test_size, :]\n",
    "test_label = y_test[0:test_size, :]\n",
    "test_label_index = np.argmax(test_label, axis = 1)\n",
    "print(len(test_label_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer1_reshape = tf.reshape(h_pool1[:, :, :, :], [-1, 1 * 32 * 32]) # [-1, 14 * 14 * 32]\n",
    "# layer1_pca = pca(layer1_reshape.eval(feed_dict ={ x: test_data}), 50)\n",
    "# layer1_tsne = tsne(layer1_pca, 2)\n",
    "# plot_scatter(layer1_tsne, test_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# layer2_reshape = tf.reshape(h_pool2[:, :, :, :], [-1, 1 * 8 * 64]) # [-1, 14 * 14 * 32]\n",
    "# layer2_pca = pca(layer2_reshape.eval(feed_dict ={x: test_data}), 50)\n",
    "# layer2_tsne = tsne(layer2_pca, 2)\n",
    "# print(len(layer2_tsne))\n",
    "# plot_scatter(layer2_tsne, test_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fc1_pca = pca(h_fc1.eval(feed_dict = {x: test_data}), 50)\n",
    "# fc1_tsne = tsne(fc1_pca, 2)\n",
    "# plot_scatter(fc1_tsne, test_label_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient = np.linspace(0, 1, num_classes)\n",
    "# gradient = np.vstack((gradient, gradient))\n",
    "# plt.imshow(gradient, cmap=plt.get_cmap(\"tab10\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "which = 0\n",
    "first_array = x_test[which].reshape(8, int(img_cols/8))\n",
    "print(test_name_list[which])\n",
    "print(x_test[which])\n",
    "plt.imshow(first_array) # color viridis\n",
    "plt.matshow(first_array, cmap = plt.get_cmap('gray'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(x_test))\n",
    "print(len(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = sess.run(y_conv, feed_dict = {x: [x_test[0]], keep_prob: 1.0 } )\n",
    "img = output[0]\n",
    "print(img)\n",
    "img = img.reshape(1, num_classes)\n",
    "plt.imshow(img, cmap='viridis')\n",
    "plt.savefig(\"out.pdf\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(img))\n",
    "print(np.where(img==np.max(img)))\n",
    "print(y_test[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmY = []\n",
    "\n",
    "for i in range(90):\n",
    "    if y_test[i][0] == 1:\n",
    "        cmY.append('allaple')\n",
    "    if y_test[i][1] == 1:\n",
    "        cmY.append('bettersurf')\n",
    "    if y_test[i][2] == 1:\n",
    "        cmY.append('elkern')\n",
    "    if y_test[i][3] == 1:\n",
    "        cmY.append('expiro')\n",
    "    if y_test[i][4] == 1:\n",
    "        cmY.append('hotbar')\n",
    "    if y_test[i][5] == 1:\n",
    "        cmY.append('kryptik_529')\n",
    "    if y_test[i][6] == 1:\n",
    "        cmY.append('kryptik_547')\n",
    "    if y_test[i][7] == 1:\n",
    "        cmY.append('loadmoney')\n",
    "    if y_test[i][8] == 1:\n",
    "        cmY.append('lydra')\n",
    "    if y_test[i][9] == 1:\n",
    "        cmY.append('mira')\n",
    "    if y_test[i][10] == 1:\n",
    "        cmY.append('morstar')\n",
    "    if y_test[i][12] == 1:\n",
    "        cmY.append('rahack')\n",
    "    if y_test[i][14] == 1:\n",
    "        cmY.append('sytro')\n",
    "    if y_test[i][15] == 1:\n",
    "        cmY.append('vobus')\n",
    "    if y_test[i][17] == 1:\n",
    "        cmY.append('zusy')\n",
    "        \n",
    "print(cmY)\n",
    "print(len(cmY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmX = []\n",
    "\n",
    "for i in range(90):\n",
    "    output = sess.run(y_conv, feed_dict = {x: [x_test[i]], keep_prob: 1.0 } )\n",
    "    img = output[0]\n",
    "    cmX.append(np.where(img==np.max(img))[0].item(0))\n",
    "    \n",
    "print(cmX)\n",
    "print(len(cmX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cmXX = []\n",
    "\n",
    "for i in range(90):\n",
    "    if cmX[i] == 0:\n",
    "        cmXX.append('allaple')\n",
    "    if cmX[i] == 1:\n",
    "        cmXX.append('bettersurf')\n",
    "    if cmX[i] == 2:\n",
    "        cmXX.append('elkern')\n",
    "    if cmX[i] == 3:\n",
    "        cmXX.append('expiro')\n",
    "    if cmX[i] == 4:\n",
    "        cmXX.append('hotbar')\n",
    "    if cmX[i] == 5:\n",
    "        cmXX.append('kryptik_529')\n",
    "    if cmX[i] == 6:\n",
    "        cmXX.append('kryptik_547')\n",
    "    if cmX[i] == 7:\n",
    "        cmXX.append('loadmoney')\n",
    "    if cmX[i] == 8:\n",
    "        cmXX.append('lydra')\n",
    "    if cmX[i] == 9:\n",
    "        cmXX.append('mira')\n",
    "    if cmX[i] == 10:\n",
    "        cmXX.append('morstar')\n",
    "    if cmX[i] == 12:\n",
    "        cmXX.append('rahack')\n",
    "    if cmX[i] == 14:\n",
    "        cmXX.append('sytro')\n",
    "    if cmX[i] == 15:\n",
    "        cmXX.append('vobus')\n",
    "    if cmX[i] == 17:\n",
    "        cmXX.append('zusy')\n",
    "        \n",
    "        \n",
    "        \n",
    "print(cmXX)\n",
    "print(len(cmXX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cmXX))\n",
    "print(len(cmY))\n",
    "\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ans = confusion_matrix(cmXX, cmY, labels=[\"allaple\", \"bettersurf\", \"elkern\", \"expiro\", \"hotbar\", \n",
    "                                    \"kryptik_529\", \"kryptik_547\", \"loadmoney\", \"lydra\", \"mira\",\n",
    "                                   \"morstar\", \n",
    "#                                           \"mydoom\", \n",
    "                                          \"rahack\", \n",
    "#                                           \"somoto\", \n",
    "                                          \"sytro\", \"vobus\", \n",
    "#                                           \"zbot\", \n",
    "                                          \"zusy\"])\n",
    "print(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "rec = recall_score(cmXX, cmY, average=\"weighted\")\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cm = ans\n",
    "true_pos = np.diag(cm)\n",
    "print(true_pos)\n",
    "print(np.sum(cm, axis=0))\n",
    "print(np.sum(cm, axis=1))\n",
    "\n",
    "\n",
    "recall = np.average(true_pos / np.sum(cm, axis=0))\n",
    "precision = np.average(true_pos / np.sum(cm, axis=1))\n",
    "\n",
    "print(precision)\n",
    "print(recall)\n",
    "\n",
    "\n",
    "f1 = 2*precision*recall / (precision+recall)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
