{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'R-CNN'\n",
    "\n",
    "initializer = tf.contrib.layers.xavier_initializer_conv2d()\n",
    "\n",
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME') # \"SAME\" tries to pad evenly left and right\n",
    "    #The stride of the sliding window for each dimension of input x. \n",
    "    \n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 1, 4, 1], strides=[1, 1, 4, 1], padding='SAME') # [1, 2, 2, 1], [1, 2, 2, 1]\n",
    "\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initializer(shape))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initializer(shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rx_train = tf.reshape(newx, [-1, 1, 128]) \n",
    "\n",
    "#unrolled through 28 time steps\n",
    "time_steps = 1\n",
    "#hidden LSTM units\n",
    "num_units = 128\n",
    "#rows of 28 pixels\n",
    "n_input = 128\n",
    "#learning rate for adam\n",
    "\n",
    "learning_rate = tf.placeholder(tf.float32)\n",
    "\n",
    "h_size = time_steps * n_input\n",
    "API_padding = True\n",
    "\n",
    "n_classes = num_classes\n",
    "\n",
    "out_weights = tf.Variable(initializer([num_units,n_classes]))\n",
    "out_bias = tf.Variable(initializer([n_classes]))\n",
    "\n",
    "#processing the input tensor from [batch_size,n_steps,n_input] to \"time_steps\" number of [batch_size,n_input] tensors\n",
    "input_x=tf.unstack(Rx_train, time_steps, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_layer = tf.contrib.rnn.BasicLSTMCell(num_units, forget_bias=1) #128 # forget_bias 類似dropout\n",
    "\n",
    "outputs, _ = tf.nn.static_rnn(lstm_layer, input_x, dtype = \"float32\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "L1 = 64\n",
    "L2 = 128\n",
    "fc = 1024\n",
    "\n",
    "# [1,16,1,64]\n",
    "W_conv1 = weight_variable([filter_x, filter_y, 1, L1]) # [filter_height, filter_width, in_channels, out_channels] [5, 5, 1, 32]\n",
    "b_conv1 = bias_variable([L1]) # 32\n",
    "\n",
    "x_image = tf.reshape(outputs, [-1, img_rows, img_cols, 1]) # [batch, in_height, in_width, in_channels] [-1, 28, 28, 1]\n",
    "\n",
    "output_conv1 = conv2d(x_image, W_conv1) + b_conv1 ###\n",
    "\n",
    "h_conv1 = tf.nn.relu(output_conv1)\n",
    "\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "\n",
    "# Second Convolutional Layer\n",
    "W_conv2 = weight_variable([filter_x, filter_y, L1, L2]) # [5, 5, 32, 64]\n",
    "b_conv2 = bias_variable([L2]) # 64\n",
    "\n",
    "output_conv2 = conv2d(h_pool1, W_conv2) + b_conv2 ###\n",
    "h_conv2 = tf.nn.relu(output_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "\n",
    "# Densely Connected Layer\n",
    "s = int(img_rows*img_cols/4/4) # hack here, 2d 2x2 2 layers = 1d 1x4 2 layers\n",
    "\n",
    "W_fc1 = weight_variable([1 * s * L2, fc]) # [7 * 7 * 64, 1024]\n",
    "b_fc1 = bias_variable([fc]) # 1024\"\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 1*s*L2]) # [-1, 7*7*64]\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "\n",
    "# Dropout\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "# Readout Layer\n",
    "W_fc2 = weight_variable([1024, num_classes]) # [1024, 14]\n",
    "b_fc2 = bias_variable([num_classes])\n",
    "\n",
    "predictions = tf.matmul(h_fc1_drop, W_fc2) + b_fc2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
